the following is a conversation with manolis kellis his fifth time on this podcast he's a professor at mit and head of the mit computational biology group he's one of the greatest living scientists in the world but he's also a humble kind caring human being that i have the greatest of honors and pleasures of being able to call a friend and now a quick few second mention of each sponsor check them out in the description it's the best way to support this podcast we got eight sleep for naps netsuite for business management software expressvpn for privacy and security on the interwebs and inside tracker for biological data choose wisely my friends also if you want to work with our amazing team we're always hiring go to lex freeman dot com slash hiring and now onto the full ad reads as always no ads in the middle i try to make this interesting i often fail but i try and if you must skip them please still check out our sponsors i enjoy their stuff maybe you will too this episode is brought to you by eight sleep and its new pod three mattress which i think of as a teleportation device into a land of dreams a place where the mind goes to escape the space time physics of this reality of the waking world anything is possible in the place of dreams the darkness that lurks in the young age shadow is possible the hope the triumph symbolizes the light at the end of the tunnel is possible all of it is possible it's all up to you i'm kinda somebody that likes both the the good and the bad of dreaming there's a cleansing aspect of a bad dream you wake up freaking out a little bit but then you realize how awesome this life is that whatever happened in the dream world is not real it's a kinda dress rehearsal for a bad event that happens in reality but it doesn't it's like in a video game you get to save do a dangerous thing screw it up and then you get to load and try again that's what a dream is anyway i love dreaming i love sleeping i love naps an innate sleep mattress is the best place to teleport into that dream world check them out and get special savings when you go to eight sleep dot com slash flex this show is also brought to you by netsuite an all in one cloud business management system it manages financials human resources inventory ecommerce and many business related details all things that i have to start figuring out i put up a job position for somebody to help me with financials all all of it i need so much help because running a business any kind of business whether it's a creative business or robotics factory or any kind of ai software company anything you do has so many components and i would say many of them don't involve any of the kind of cutting edge engineering and design and brainstorming and innovation and research and all that kind of stuff you have to do all the basic minutia the glue that ties together people and makes the whole thing run and i think you should use the best tool for that job and netsuite is something i can definitely recommend as a great tool you can start now with no payment or interest for six months go to netsuite dot com slash lex to access their one of a kind financing program that's netsuite dot com slash lex this show is also brought to you by expressvpn my comrade my friend the piece of software that has accompanied me through darkness and light for many years way before i had a podcast way before i have found my way though i am still forever lost and you if you too are forever lost perhaps it will also warm your heart as a dead mind first of all practically speaking let's put the romantic stuff aside you should be using a vpn on the internet and expressvpn is the vpn i've used and can highly highly highly recommend by the way i apologize for the coarseness of my voice i've been feeling a little bit under the weather whatever the heck that expression actually means there there's always chat g p t that can ask the question but i'm not going to i'm just gonna go with it gonna wing it gonna wing it is another funny expression right wing it what does that mean probably has to do with birds and the fact that bird flight is a kind of chaotic process that's not amenable to clear dynamical system modeling that for example an airplane is but let us return to the piece of software you should be using to warm your heart and to protect your privacy on the internet go to express c p n dot com slash lex pod for an extra three months free this show is also brought to you by insidetracker a service i use to track biological data that comes from my body there's that song it's my party and i'll cry if i want to and i used to think it said it's my body and i'll cry if i want to i don't know what i thought that actually meant but it's a good song it's a silly song it's my party and i'll cry if i want to cry if i want to cry if i want to you would cry too if it happened to you anyway speaking of which we're going hard on the tangents today i like data that comes from my body that is then used in machine learning algorithms to make decisions or recommendations of what i should do with said body lifestyle choices diet maybe in the future it'd be career advice all kinds of stuff dating friends anything you know but basically health stuff medicine i think and that's the obvious way you should be figuring out what to do with your body is at least in large part based on the data that comes from your body and not just once but many times over and over and over and over insidetracker pioneering the data collection so there's the blood test then then can extract all kinds of information give you advice i highly recommend them get special savings for a limited time when you go to insight tracker dot com slash lex this is a lex fridman podcast to support it please check out our sponsors in the description and now dear friends here's manoas kallis good to see you first of all man flex i've missed you i think you've changed the lives of so many people that i know and it's truly like such a pleasure to be back such a pleasure to see you grow to sort of reach so many different aspects of your own personality thank you for the love you always give me some support and love i just can't i i i i'm forever grateful for that it's lovely to see a fellow human being who has that love who basically does not judge people and there's so many judgmental people out there and it's just so nice to see this beacon of openness so what makes me one instantiation of human irreplaceable do you think as we enter this increasingly capable age of increasingly capable ai i have to ask what do you think makes humans irreplaceable so humans are irreplaceable because of the baggage that we talked about so we talked about baggage we talked about the fact that every one of us has effectively relearned all of human civilization in their own way so every single human has a unique set of genetic variants that they've inherited some common some rare and some make us think differently some make us have different personalities they say that a a parent with one child believes in genetics a parent with multiple children understands genetics just how different kids are and and my three kids have dramatically different personalities ever since the beginning so one thing that makes us unique is that every one of us has a different hardware the second thing that makes us unique is that every one of us has a different software uploading of all of human society all of human civilization all of human knowledge we don't we're not born knowing it we're not like i don't know birds that learn how to make a nest through genetics and will make a nest even if they've never seen one we are constantly relearning all of human civilization so that's the second thing and the third one that actually makes humans very different from ai is that the baggage we carry is not experiential baggage it's also evolutionary baggage so we have evolved through rounds of complexity so just like ogres have layers and shrek has layers humans have layers there's the cognitive layer which is sort of the outer you know most the the latest evolutionary innovation this enormous neocortex that we have evolved and then there's the emotional baggage underneath that and then there's all of the fear and fright and flight and all of these kinds of behaviors so ai only has a neocortex ai doesn't have a limbic system it doesn't have this complexity of human emotions which make us so i think beautifully complex so beautifully intertwined with our emotions with our instincts with our you know sort of gut reactions and all of that so i think when humans are trying to suppress that aspect the sort of quote unquote more human aspect towards a more cerebral aspect i think we lose a lot of the creativity we lose a lot of the you know freshness of humans and i think that's quite irreplaceable so we can look at the entirety of people that are alive today maybe all humans who have ever lived yeah and map them in this high dimensional space and there's probably a a center a a center of mass for that mapping and a lot of us deviate in different directions so the the variety of directions in which we all deviate from that center is vast i would like to think that the center is actually empty yes that basically humans are just so diverse from each other that there's no such thing as an average human that every one of us has some kind of complex baggage of emotions intellectual you know motivational behavioral traits that it's not just one sort of normal distribution we deviate from it there's just so many dimensions that we're kind of hitting the sort of sparseness the curse of dimensionality where it's actually quite sparsely populated and i don't think you have an average human being so what makes us unique in part is the diversity and the capacity for diversity and the capacity of the diversity comes from the entire evolutionary history so there's just so many ways we can vary from each other yeah i would say not just the capacity but the inevitability of diversity basically it's in our hardware we are wired differently from each other my siblings and i are completely different my kids from each other are completely different my my my wife has she's like number two of six siblings from from a distance they look the same but then you get to you know you get to know them every one of them is completely different but sufficiently the same that the differences interplay with each other so that's the interesting thing where the diversity is functional it's useful so it's like we're close enough to where we notice the diversity and it doesn't completely destroy the possibility of like effective communication interaction so it's we're still the same kind of thing so what i said in one of our earlier podcast is that if humans realize that we're ninety nine point nine percent identical we would basically stop fighting with each other like we are really one human species and we are so so similar to each other and if you look at the alternative if you look at the next thing outside humans like it's been six million years that we haven't had a relative so it's it's truly extraordinary that that we're we're kind of like this dot in outer space compared to the rest of life on earth when you think about evolving through rounds of complexity can you maybe elaborate such a beautiful phrase beautiful thought that there's layers of complexity that make so so with software sometimes you're like oh let's like build version two from scratch but this doesn't happen in evolution in evolution you layer in additional features on top of old features so basically when like every single time my cells divide i'm a yeast like i'm a unicellular organism and then cell division is basically identical every time i breathe in and my lungs expand i'm basically you know like every time my heart beats i'm a fish so basically that i still have the same heart like very very little has changed the blood going through my veins the oxygen the you know our immune system we're basically primates our social behavior were basically new world monkeys and old world monkeys we're basically this this concept that every single one of these behaviors can be traced somewhere in evolution and that all of that continues to live within us is also a testament to not just not killing other humans for god's sake but like not killing other species either like just to realize just how united we are with nature and that all of these biological processes have never ceased to exist they're continuing to live within us and then just the neocortex and all of the reasoning capabilities of humans are built on top of all of these other species that continue to live breathe divide metabolize fight off pathogens all continued inside us so you think the neocortex the whatever reasoning is that's the the latest feature in the in the latest version of this journey it's it's extraordinary that humans have evolved so much in so little time again if you look at the the timeline of evolution you basically have billions of years to even get to a dividing cell and then a multicellular organism and then a complex body plan and then these incredible senses that we have for perceiving the world the fact that bats can fly and they evolved flight they evolved sonar in the span of a few million years i mean it's just extraordinary how much evolution has kind of sped up and all of that comes through this evolvability the fact that we took a while to get good at evolving and then once you get good at evolving you can sort of you have modularity built in you have hierarchical organizations built in you have all of these constructs that allow meaningful changes to occur without breaking the system completely if you look at a traditional genetic algorithm the way that humans designed them in the sixties you can only evolve so much and as you evolve a certain amount of complexity the number of mutations that move you away from something functional exponentially increases mhmm and the number of mutations that move you to something better exponentially decreases so the probability of evolving something so complex becomes infinitesimally small as you get more complex but with evolution it's almost the opposite almost the exact opposite that it appears that it's speeding up exactly as complex complexity is increasing and i think that's just the system getting good at evolving where do you think it's all headed do you ever think about where try to visualize the entirety of the evolutionary system and see if there's an arrow to it and a destination to it so the best way to understand the future is to look at the past if you look at the trajectory then you can kind of learn something about the direction in which we're heading and if you look at the trajectory of life on earth it's really about information processing so the concept of the senses evolving one after the other you know being like bacteria are able to do chemotaxis this can means moving towards a chemical gradient and that's the first thing that you need to sort of hunt down food the next step after that is being able to actually perceive light so all life on this planet and all life that we know about evolved on this rotating rock every twenty four hours you get sunlight and dark sunlight and dark and light is a source of energy light is also information about where is up light is all kinds of you know things so you can you can basically now start perceiving light and then perceiving shapes beyond just the sort of single photoreceptor you can now have complex eyes or multiple eyes and then start perceiving motion or perceiving direction perceiving shapes and then you start building infrastructure on the cognitive apparatus to start processing this information and making sense of the environment building more complex models of the environment so if you look at that trajectory of evolution what we're experiencing now and humans are basically according to this sort of information theoretic view of evolution humans are basically the next natural step and it's perhaps no surprise that we became the dominant species of the planet because yes there's so many dimensions in which some animals are way better than we are but but at least on the cognitive dimension we're just simply unsurpassed on this planet and and perhaps the universe but the the concept that if you now trace this forward we talked a little bit about evolvability and how things get better at evolving one possibility is that the next layer of evolution builds the next layer of evolution and what we're looking at now with humans and ai is that having mastered this information capability that humans have from this quote unquote old hardware this basically you know biological evolved system that kind of you know somehow in the environment of africa and then in subsequent environments of sort of dispersing through the globe was evolutionarily advantageous that has now created technology which now has a capability of solving many of these cognitive tasks it doesn't have all the baggage of the previous evolutionary layers but maybe the next round of evolution on earth is self replicating ai where we're actually using our current smarts to build better programming languages and the programming languages to build you know chat gpt and that to then build the next layer of software that will then sort of help ai speed up and it's lovely that we're coexisting with this ai that sort of the creators of this next layer of evolution this next stage are still around to help guide it and hopefully will be for the rest of eternity as partners but it's also nice to think about it as just simply the next stage of evolution where you've kind of extracted away the biological needs like if you look at animals most of them spend eighty percent of their waking hours hunting for food or building shelter humans maybe one percent of that time and then the rest is left to creative endeavors an ai doesn't have to worry about shelter etcetera so basically it's all living in the cognitive space so in a way it might just be a very natural sort of next step to think about evolution and that's that's on the on the sort of purely cognitive side if you now think about humans themselves the ability to understand and comprehend our own genome again the ultimate layer of introspection gives us now the ability to even mess with this hardware not just augment our capabilities through interacting and collaborating with ai but also perhaps understand the neural pathways that are necessary for you know empathetic thinking for for justice for this and this and that and sort of help augment human capabilities through you know neuronal interventions through chemical interventions through electrical interventions to basically help steer the human you know bag of hardware that we kind of evolved with into greater capabilities and then ultimately by understanding not just the wiring of neurons and the functioning of neurons but even the genetic code we could even at one point in the future start thinking about well can we get rid of psychiatric disease can we get rid of neurodegeneration can we get rid of dementia and start perhaps even augmenting human capabilities not just getting rid of disease can we tinker with the genome with the hardware or getting closer to the hardware without having to deeply understand the baggage in the way we've disposed of the baggage in our software systems with ai to some degree not fully but to some degree can we do the same with the genome or is the genome deeply integrated into this baggage i wouldn't wanna get rid of the the baggage the baggage would makes us awesome so the fact that i'm sometimes angry and sometimes hungry and sometimes hangry is perhaps contributing to my creativity i don't want to be dispassionate i don't want to be another like you know robert i you know i want to get in trouble and i want to sort of say the wrong thing and i want to sort of you know make an awkward comment and sort of push myself into you know reactions and responses and things that can get just people thinking differently and i think our society is moving towards a humorless space where everybody's so afraid to say the wrong thing that people kind of start quitting en masse and start like not liking their jobs and stuff like that maybe we should be kind of embracing that human aspect a little bit more in all of that baggage aspect and not necessarily thinking about replacing it on the contrary like embracing it instead of this coexistence of the cognitive and the emotional hardwares so embracing and celebrating the diversity that springs from the baggage versus kind of pushing towards and empowering this kind of pull towards conformity yeah and in fact with the advent of ai i would say and these seemingly extremely intelligent systems that sort of can form can perform tasks that we thought of as extremely intelligent at the blink of an eye this might democratize intellectual pursuits instead of just simply wanting the same type of brains that you know carry out specific ways of thinking we can like instead of just always only wanting say the mathematically extraordinary to go to the same universities what you could see simply say is like who needs that anymore you know we now have ai maybe what we should really be thinking about is the diversity and the power that comes with the diversity where ai can do the math and then we should be getting a bunch of humans that sort of think extremely differently from each other and maybe that's the true cradle of innovation but ai can also these large language models can also be with just a few prompts essentially fine tuned to be diverse from the center so the prompts can really take you away into unique territory you can ask the model to act in a certain way and it'll start to act in that way is that possible that the language models could also have some of the magical diversity that makes us so damn interesting so i would say humans are the same way so basically when you when you sort of prompt humans to basically you know give an environment to act a particular way they change their own behaviors and you know the old saying is show me your friends and i'll tell you who you are mhmm more like show me your friends and i'll tell you who you'll become mhmm so it's not necessarily that you choose friends that are like you but i mean that's the first step but then the second step is that you know the kind of behaviors that you find normal in your circles are the behaviors that you'll start espousing and that type of meta evolution where every action we take not only shapes our current action and the result of this action but it also shapes our future actions by shaping the environment in which those future actions will be taken every time you you carry out a particular behavior it's not just a consequence for today but it's also a consequence for tomorrow because you're reinforcing that neural pathway mhmm so in a way self discipline is a self fulfilling prophecy and by behaving the way that you wanna behave and choosing people that are like you and sort of exhibiting those behaviors that are sort of desirable you end up creating that that environment as well so that it is a kind of life itself is a kind of prompting mechanism super complex the the friends you choose the environments you choose the way you modify the environment that you choose yes but that seems like that process is much less efficient than a large language model you can literally get a large language model through a couple of prompts to be a mix of shakespeare and david bowie right you can very aggressively change in a way that's stable and convincing you really transform through a couple of prompts the the behavior of the model into something very different from the original so well before chatgpt yeah i would tell my students just ask you know what would manoli say right now and you you guys all have a pretty good emulator of me right now yes and i don't know if you know the programming paradigm of the rubber duckling where you basically explain to the rubber duckling that's just sitting there exactly what you did with your code and why you have a bug and just by the act of explaining you'll kind of figure it out yes i woke up one morning from a dream where i was giving a lecture in this amphitheater and one of my friends was basically giving me some deep evolutionary insight on how cancer genomes and cancer cells evolve and i woke up with a very elaborate discussion that i was giving and a very elaborate set of insights that he had that i was projecting onto my friend in my sleep and obviously this was my dream so my own neurons were capable of doing that but they only did that under the prompt of you are now piyush gupta you are a professor in cancer genomics you're an expert in that field what do you say so i feel that we all have that inside us that we have that capability of basically saying i don't know what the right thing is but let me ask my virtual ex what would you do and virtual ex would say be kind i'm like oh yes or something like that and even though i myself might not be able to do it unprompted and the my favorite prompt is think step by step and i'm like you know this also works on my ten year old when he tries to solve a math equation all in one step i know exactly what mistake he'll make but if i prompt it with oh please think step by step then it sort of gets you in a mindset and i think it's also part of the way that jgpt was actually trained this whole sort of human in the loop reinforcement learning has probably reinforced these types of behaviors whereby having this feedback loop you kind of aligned ai better to the prompting opportunities by humans yeah prompting human like reasoning steps the step by step kind of thinking yeah but it does seem to be i suppose it just puts a mirror to our own capabilities and so we can be truly impressed by our own cognitive capabilities because the variety of what you can try because we don't usually have this kinda we can't play with our own mind rigorously through python code right yeah so this allows us to really play with all all of human wisdom and knowledge or at least knowledge at our fingertips and then mess with that little mind that can think and speak in all kinds of ways what's unique is that as i mentioned earlier every one of us was trained by a different subset of that's right human culture and jgpt was trained on all of it yeah and the difference there is that it probably has the ability to emulate almost every one of us yeah the fact that you can figure out where that is in cognitive behavioral space just by a few prompts is pretty impressive mhmm but the fact that that exists somewhere is you know absolutely beautiful and the fact that it's encoded in an orthogonal way from the knowledge i think is also beautiful the fact that somehow through this extreme overparameterization of ai models it was able to somehow figure out that context knowledge and form are separable mhmm and that you can sort of describe scientific knowledge in a haiku in the form of i don't know shakespeare or something that tells you something about the the decoupling and the decoupleability of these types of aspects of human psyche and that's part of the science of this whole thing so these large language models are you know days old in terms of this kind of leap that they've taken and it'll be interesting to do this kind of analysis on them of contact of the separation of context form and knowledge where exactly does that happen yeah there's already sort of initial investigations but it's very hard to figure out where is there a particular parameter set of parameters that are responsible for a particular piece of knowledge or a particular context or a particular style of speaking so with convolutional neural networks interpretability had many good advances mhmm because we can kind of understand them there's a structure to them yeah there's a locality to them and we can kind of understand that different layers have different sort of ranges that they're looking at so we can look at activation features and basically see where you know where does that correspond to with large language models it's perhaps a little more complicated but i think it's still achievable in the sense that we could kind of ask well what kind of prompts does this generate if i sort of drop out this part of the network then what happens and sort of start getting at a language to even describe these types of aspects of human behavior or psychology if you wish from the spoken part in the language part and the advantage of that is that it might actually teach us something about humans as well like you you know we might not have words to describe these types of aspects right now but when somebody speaks in a particular way it might remind us of a friend that we know from here and there and there and if we had better language for describing that these concepts might become more apparent in our own human psyche and then we might be able to encode them better in machines themselves i both probably you and i would have certain interest with the base model with openaccow's the base model which is before the the alignment of the reinforcement learning with human feedback and and before the ai safety based kind of censorship of the model it would be fascinating to explore to investigate the ways that the model can generate hate speech the kind of hate that humans are capable of it would be fascinating or the kind of of course like sexual language or the kind of romantic language or the all kinds of ideologies can i get it to be a communist can i get it to be a fascist can i get it to be a capitalist can i get it to be all these kinds of things and see which parts get activated and not because it'll be fascinating to sort of explore at the individual mind level and at a societal level where do these ideas take hold what is the fundamental core of those ideas maybe the communism fascism capitalism democracy are all actually connected by the fact that the human heart the human mind is drawn to ideology to so a centralizing idea and maybe we need a neural network to remind us of that i like the concept that the human mind is somehow tied to ideology and i think that goes back to the promptability of jgpt the fact that you can kind of say well think in this particular way now and the fact that humans have invented words for encapsulating these types of behaviors and it's hard to know how much of that is innate and how much of that was like passed on from language to language but basically if you look at the evolution of language you can kinda see how young are these words in the history of language evolution that describe these types of behaviors like you know kindness and anger and jealousy etcetera if these words are very similar from language to language it might suggest that they're very ancient if they're very different it might suggest that this concept may have emerged independently in each different language and so on and so forth so looking at the phylogeny the history the evolutionary traces of language at the same time as people moving around that we can now trace thanks to genetics is a fascinating way of understanding the human psyche and also understanding sort of how these types of behaviors emerge and to go back to your idea about sort of exploring the system unfiltered i mean in a way the psychiatric hospitals are full of those people so basically people whose mind is uncontrollable who have kind of gone adrift in specific locations of their psyche and i do find this fascinating basically you know watching movies that are trying to capture the essence of troubled minds i think is teaching us so much about our everyday selves because many of us are able to sort of control our minds and are able to somehow somehow hide these emotions and but every time i see somebody who's troubled i i see versions of myself maybe not as extreme but i can sort of empathize with these behaviors and you know i see bipolar i see schizophrenia i see i see depression i see autism i see so many different aspects that we kind of have names for and crystallize in specific individuals and i think all of us have that all of us have sort of just this multidimensional brain and genetic variations that push us in these directions environmental exposures and traumas that push us in these directions environmental behaviors that are reinforced by the kind of friends that we chose or friends that we were stuck with because of the environments that we grew up in so in a way a lot of these types of behaviors are within the vector span of every human it's just that the magnitude of those vectors is generally smaller for most people because they haven't inherited that particular set of genetic variants or because they haven't been exposed to those environments basically or something about the mechanism of reinforcement learning with human feedback didn't quite work for them so it's fascinating to think about that's what we do we have this capacity to have all these psychiatric or behaviors associated with psychiatric disorders but we through the alignment process as we go through the parents we kind of we know to suppress them yeah we know how to control every human that grows up in this in this world spends several decades being shaped into place yeah and without that you know maybe we would have the unfiltered judge of eighty four every baby is basically a raging narcissist not all of them not all of them believe it or not it's remarkable like i remember like watching my kids grow up and again like yes part of their personality has stayed the same but also in different phases to their life they've gone through these dramatically different types of behaviors and you know my daughter basically saying you know basically one kid saying oh i want the bigger piece the other one saying oh everything must be exactly equal and the third one saying i'm okay yeah you you know i might have to have the smaller part don't worry about me even in the early days in the early days of development yeah it's just extraordinary to sort of see these dramatically different like i mean my wife and i you know are are very different from each other but we also have you know six million variants six million loci each if you wish if you just look at common variants we also have a bunch of rare variants that are inherited in more mendelian fashion and now you have you know an infinite number of possibilities for each of the kids so basically it's two to the six million just from the common variance and then if you like layer in the rare variance so let me talk a little bit about common variance and rare variance so if you look at just common variance they're generally weak effect because selection selects against strong effect variants so if something like has a big risk for schizophrenia it won't rise to high frequency so the ones that are common are by definition by selection only the ones that had relatively weak effect and if all of the variance associated with personality with cognition and all aspects of human behavior were weak effect variance then kid would basically be just averages of their parents if it was like thousands of loci just by law law of large numbers the average of two large numbers would be you know very robustly close to that middle but what we see is that kids are dramatically different from each other so that basically means that in the context of that common variation you basically have rare variants that are inherited in a more mendelian fashion that basically then sort of govern likely many different aspects of human behavior human biology and human psychology and that's again like if you look at sort of a person with schizophrenia their identical twin has only fifty percent chance of actually being diagnosed with schizophrenia so that basically means there's probably developmental exposures environmental exposures trauma all kinds of other aspects that can shape that and if you look at siblings for the common variance it kind of drops off exponentially as you would expect with sharing fifty percent of your genome twenty five percent of your genome you know twelve point five percent of your genome etcetera with more and more distant cousins but the fact that siblings can differ so much in their personalities that we observe every day it can't all be nurture basically you know we we've like again as parents we we spend enormous amount of energy trying to fix quote unquote the nurture part trying to you know get them to share get them to be kind get them to be open get them to trust each other like you know like overcome the prisoner's dilemma of you know if if everyone fends for themselves we're all gonna live in a horrible place but if we're a little more altruistic then we're all gonna be in a better place and i think it's not like we treat our kids differently but but they're they're just born differently so in a way as a geneticist i have to admit that there's only so much i can do with nurture that nature definitely plays a big component the the selection of variants we have the common variants and the rare variants what what can we say about the landscape of possibility they create if you could just linger on that so the the selection of rare rare variants is is divine how how do we get the ones that we get is is it just laden in that giant evolutionary baggage so i'm gonna talk about regression why do we call it regression mhmm and the concept of regression to the mean the fact that when fighter pilots in a dogfight did amazingly well they would give them rewards and then the next time they're in a dogfight they would do worse mhmm so then you know the navy basically realized that wow this or at least interpreted that as wow we're ruining them by praising them and then they're gonna perform worse the statistical interpretation of that is regression of the mean the fact that you're an extraordinary pilot you've been trained in an extraordinary fashion that pushes your mean further and further to extraordinary achievement and then in some dogfights you'll just do extraordinarily well the probability that the next one will be just as good is almost nil because this is the peak of your performance and just by statistical odds the next one will be another sample from the same underlying distribution which is gonna be a little closer to the mean so regression analysis takes its name from this type of realization in the statistical world now if you now take humans you basically have people who have achieved extraordinary achievements einstein for example you know you would call him for example the epitome of human intellect mhmm does that mean that all of his children and grandchildren will be extraordinary geniuses it probably means that they're sampled from the same underlying distribution but he was probably a rare combination of extremes in addition to these common variants so you can basically interpret your kid's variation for example as well of course they're gonna be some kind of sampled from the average of the parents with some kind of deviation according to the specific combination of rare variance that they have that they have inherited so you know given all that the you know the possibilities are endless as to sort of where you should be but you should always interpret that with well it's probably an alignment of nature and nurture and the nature has both the common variants that are acting kinda like the law of large numbers and the rare variants that are acting more in a mendelian fashion and then you layer in the nurture which again in everyday action we make we shape our future environment but the genetics we inherit are shaping the future environment of not only us but also our children so there's this weird nature nurture interplay and self reinforcement where you're kind of shaping your own environment but you're also shaping the environment of your kids and your kids are gonna be born in the context of your environment that you've shaped but also with a bag of genetic variants that they have inherited and there's just so much complexity associated with that when we start blaming something on nature it might just be nurture it might just be that well yes they inherited the genes from the parents but they also you know were shaped by the same environment so it's very very hard to untangle the two and you should always realize that nature can influence nurture nurture can influence nature or at least be correlated with and predictive of and so on and so forth so i love thinking about that distribution that you mentioned and here's where i can be my usual ridiculous self and i sometimes think about that army of sperm cells however many hundreds of thousands there are and i kinda think of all the possibilities there because there's a lot of variation and one gets to win is is that a not a random one is is it a totally ridiculous way to think about no not at all to so i would say evolutionarily we are a very slow evolving species basically the generations of humans are a terrible way to do selection what you need is processes that allow you to do selection in a smaller tighter loop yep and part of what if you look at our immune system for example it evolves at a much faster pace than humans evolve because there is actually an evolutionary process that happens within our immune cells as they're dividing there's basically vdj recombination that basically creates this extraordinary wealth of antibodies and antigens against the the environment and basically all these antibodies are now recognizing all these antigens from the environment and they send signals back that cause these cells that recognize the known self to multiply so that basically means that even though viruses evolve at millions of times faster than we are we can still have a component of ourselves which is environmentally facing which is sort of evolving at not the same scale but very rapid pace sperm expresses perhaps the most proteins of any cell in the body and part of the thought is that this might just be a way to check that the sperm is intact in other words if you waited until that human has a liver and starts eating solid food and you know sort of filtrates away you know or kidneys or stomach etcetera basically if you wait until these mutations you know manifest late late in life then you would end up not failing fast and you would end up with a lot of failed pregnancies and a lot of later onset you know psychiatric illnesses etcetera if instead you basically express all of these genes at the sperm level and if they misform that basically cause the sperm to cripple then you have at least on the male side the ability to exclude some of those mutations and on the female side as the egg develops there's probably a similar process where you could you could sort of weed out eggs that are just not you know carrying beneficial mutations or at least that are carrying highly detrimental mutations so you can basically think of the evolutionary process in a nested loop basically where there's an inner loop where you get many many more iterations to to run and then there's an outer loop that moves at a much slower pace and going back to the next step of evolution of possibly designing systems that we can use to sort of complement our own biology or to sort of eradicate disease and you name it or at least mitigate some of the i don't know psychiatric illnesses neurodegenerative disorders etcetera you can basically and also you know metabolic immune cancer you name it simply engineering these mutations from rational design might be very inefficient if instead you have an an evolutionary loop where you're kind of growing neurons on a dish and you're exploring evolutionary space and you're sort of shaping that one protein to be better adapt that sort of i don't know recognizing light or communicating with other neurons etcetera you can basically have a smaller evolutionary loop that you can run thousands of times faster than the speed it would take to evolve humans for another million years so i think it's important to think about sort of this evolvability as a set of nested structures that allow you to sort of test many more combinations but in a more fixed setting yeah that's fascinating that's the the mechanism there is for for sperm to express proteins to create a testing ground early on so that the the failed designs don't make it yeah i mean in design of engineering systems fail fast is one of the principles you learn yeah like basically you assert something why do you assert that because if that something ain't right you better crash now than sort of let it crash at an unexpected time and in a way you can think of it as like twenty thousand assert functions assert protein can fold assert protein can fold yeah and if any of them fail that sperm is gone well i just like the fact that i'm the winning sperm i'm the result of the the winner winning hashtag winning my my wife always plays me this french song that actually sings about that it's like you know remember in life we were all the first one time so at least once we were at least one time you were the first i should mention this is a brief tangent back to the place where we came from yeah which is the base model that i mentioned for openai which is before the reinforcement learning with human feedback and you kinda give this metaphor of it being kind of like a psychiatric hospital i like that because it's basically all of these different angles at once like you basically have the more extreme versions of human psyche so the interesting thing is i've talked with folks in openai quite a lot and they say it's extremely difficult to work with that model yeah kinda like it's extremely difficult to work with some humans the parallels there are very interesting because once you run the alignment process it's much easier to interact with it yeah but it makes you wander with the capacity what the underlying capability of the human psyche is as in the same way that what is the underlying capability of a large language model and remember earlier when i was basically saying that part of the reason why it's so prompt malleable is because of that alignment problem did that alignment work it's kind of nice that the engineers at openai have the same interpretation that you know in fact it is that and this whole concept of easier to work with i i wish that we could work with more diverse humans in a way and and sort of that's one of the possibilities that i see with the advent of these large language models the fact that it gives us the chance to both dial down friends of ours that we can't interpret or that are just too edgy mhmm to sort of really truly interact with where you could have a real time translator just the same way that you can translate english to japanese or chinese or korean by like real time adaptation mhmm you could basically suddenly have a conversation with your favorite extremist on either side of the spectrum and just dial them down a little bit of course not you and i but you could have friends that is who's a complete asshole but it's a a different base level so you could actually tune it down to like okay they're not actually being an asshole there yes this is they're actually expressing love right now it's just that this is a they have their way of of doing that and they probably live in new york if we're just to pick a random location so so that yeah so you can basically layer out contexts you can basically say oh let me change new york to texas and let me change you know extreme left to extreme right or somewhere in the middle or something and i also like the concept of being able to listen to the information without being dissuaded by the emotions in other words everything humans say has an intonation has some kind of background that they're coming from it reflects the way that they're thinking of you reflects the impression that they have of you and all of these things are intertwined but being able to disconnect them being able to sort of i mean self improvement is one of the things that i'm constantly working on and being able to receive criticism from people who really hate you is difficult because it's layered in with that hatred but deep down there's something that they say that actually makes sense or people who love you might layer it in a way that doesn't come through but if you're able to sort of disconnect that emotional component from the sort of self improvement and basically when somebody says woah that was a bunch of bullshit did you ever do the control this and this and that mhmm you could just say oh thanks for the very interesting presentation you know i'm wondering what about that control then suddenly you're like oh yeah of course i'm gonna run that control that's a great idea yeah instead of that was a bunch of bs you're like you're sort of hitting on the brakes and you're trying to push back against of that so any kind of criticism that comes after that is very difficult to interpret in a positive way because it helps reinforce the negative assessment of your work mhmm when in fact if we disconnected the technical component from the negative assessment then you're embracing the negative then you're embracing the technical component you you're gonna fix it whereas if it's coupled with and if that thing is real and and i'm right about your mistake then it's a it's a bunch of b s then suddenly you're like you're gonna try to prove that that mistake does not exist yeah it's fascinating to like carry the information this is what you're essentially able to do here is you carry the information in the rich complexity that information contains so it's not actually dumbing it down in some way exactly still expressing it but taking off but you can dial the the the the emotional the emotion side of it yeah which is probably so powerful for the internet or for social networks again when it comes to understanding each other one of like for example i don't know what it's like to go through life with a different skin color i don't know how people will perceive me i don't know how people will respond to me we don't often have that experience but in a virtual reality environment or in a sort of ai interactive system you could basically say okay now make me chinese or make me south african or make me you know nigerian you can change the accent you can change layers of that contextual information and then see how the information is interpreted and you can rehear yourself through a different angle you can hear others you can have others react to you from a different package and then hopefully we can sort of build empathy by learning to disconnect all of these social cues that we get from like how a person is dressed you know if they're wearing a hoodie or if they're wearing a shirt or if they're wearing a you know jacket you get very different emotional responses that you know i wish we could overcome as humans and perhaps large language models and augmented reality and deep fakes can kind of help us overcome all that in what way do you think these large language models and the thing they give birth to in the ai space will change this human experience the human condition the things we've talked across many podcasts about that makes life so damn interesting and rich love fear fear of death all of it if we could just begin kind of thinking about how does it change for the good and the bad the human condition human society is extremely complicated we have come from a hunter gatherer society to an agricultural and farming society where the goal of most professions was to eat and to survive and with the advent of agriculture the ability to live together in societies humans could suddenly be valued for different skills if you don't know how to hunt but you're an amazing potterer then you fit in society very well because you can sort of make your pottery and you can barter it for rabbits that somebody else caught and the person who hunts the rabbits doesn't need to make pots because you're making all the pots and that specialization of humans is what shaped modern society and with the advent of currencies and governments and you know credit cards and bitcoin you basically now have the ability to exchange value for the kind of productivity that you have so basically i make things that are desirable to others i can sell them and buy back food shelter etcetera with ai the concept of i am my profession might need to be revised because i defined my profession in the first place as something that humanity needed that i was uniquely capable of delivering but the moment we have ai systems able to deliver these goods for example writing a piece of software or making a self driving car or interpreting the human genome then that frees up more of human time for other pursuits mhmm this could be pursuits that are still valuable to society i could basically be ten times more productive at interpreting genomes and do a lot more or i could basically say oh great the interpreting genome's part of my job now now only takes me five percent of the time instead of sixty percent of the time so now i can do more creative things i can explore not new career options but maybe new directions for my research lab i can sort of be more productive contribute more to society and if you look at this giant pyramid that we have built on top of the subsistence economy what fraction of us jobs are going to feeding all of the us less than two percent basically the the the gain in productivity is such that ninety eight percent of the economy is beyond just feeding ourselves and that basically means that we kinda have built this system of interdependencies of needed or useful or valued goods that sort of make the economy run that the vast majority of wealth goes to other what we now call needs but used to be wants mhmm so basically i wanna fly a drone i wanna buy a bicycle i wanna buy a nice car i wanna have a nice home i wanna etcetera etcetera etcetera so and and then sort of what is my direct contribution to my eating i mean i'm i'm i'm doing research on the human genome i mean this will help humans it will help all humanity but how is that helping the person who's giving me poultry or vegetables so in a way i see ai as perhaps leading to a dramatic rethinking of human society if you think about sort of the economy being based on intellectual goods that i'm producing what if ai can produce a lot of these intellectual goods and satisfies that need does that now free humans for more artistic expression for more emotional maturing for basically having a better work life balance mhmm being able to show up for your two hours of work a day or two hours of work like three times a week with like immense rest and preparation and exercise and you're sort of clearing your mind until you have these two amazingly creative hour hours you basically show up at the office as your ai is busy answering your phone call making all your meetings you know revising all your papers etcetera and then you show up for those creative hours and you're like alright autopilot i'm on and then you can basically do so so much more that you would perhaps otherwise never get to because you're so overwhelmed with these mundane aspects of your of your job so i feel that ai can truly transform the human condition from realizing that we don't have jobs anymore we now have vocations and there's this beautiful analogy of three people laying bricks and somebody comes over and asks the first one what are you doing he's like oh i'm laying bricks second one what are you doing i'm building a wall and the third one what are you doing i'm building this beautiful cathedral so in a way the first one has a job the last one has a vocation and if you ask me what are you doing oh i'm editing a paper then i have a job what are you doing understanding human disease circuitry i have a vocation mhmm so in a way being able to allow us to enjoy more of our vocation by taking away offloading some of the job part of our daily activities so we all become the the builders of cathedrals correct yeah and we follow intellectual pursuits artistic pursuits i wonder what how that really changes at a scale of several billion people everybody playing in the space of ideas in the space of creations so ideas maybe for some of us maybe you and i are in the job of ideas but other people are in the job of experiences other job are other people in the the job of emotions of dancing of creative artistic expression of you know skydiving and you name it so basically these again the beaut of human diversity is exactly that that what rocks my boat might be very different from what rocks other people's boat and what i'm trying to say is that maybe ai will allow humans to truly like not just look for but find meaning and sort of you don't need to work mhmm but you need to keep your brain at ease and the way that your brain will be at ease is by dancing and creating these amazing you know movements or creating these amazing paintings or creating i don't know something that that sort of changes that that touches at least one person out there that sort of shapes humanity through that process and instead of working your you know mundane programming job where you like hate your boss and you hate your job and you say you hate that darn program etcetera you're like well i don't need that i can you know offload that and i can now explore something that will actually be more beneficial to to humanity because the mundane parts can be offloaded i wonder if it localizes our all the things you've mentioned all the vocations so you mentioned that you and i might be playing in the space of ideas but there's two ways to play in the space of ideas both of which we're currently engaging mhmm and so one is the communication of that to other people it could be a classroom full of students but it could be a podcast it could be something that's that's shown on youtube and so on or it could be just the act of sitting alone and playing with ideas in your head or maybe with a loved one having a conversation that nobody gets to see yeah the experience of just sort of looking up at the sky and wondering different things maybe quoting some philosophers from the past and playing with those little ideas and that little exchange is forgotten forever but you got to experience it and maybe we i wonder if it localizes that exchange of ideas for that with ai it'll become less and less valuable to communicate with a large group of people that you will live life intimately and and richly just with that circle of meat bags that you seem to love so the first is even if you're alone in a forest having this amazing thought when you exit that forest the baggage that you carry has been shifted has been altered by that thought when i bike to work in the morning i listen to books and i'm alone no one else is there i'm having that experience by myself and yet in the evening when i speak with someone an idea that was formed there could come back sometimes when i fall asleep i fall asleep listening to a book yeah and in the morning i'll be full of ideas that i never even processed consciously i'll process them unconsciously and they will shape that baggage that i carry that will then shape my interactions and again affect ultimately all of humanity in some butterfly effect minute kind of way so that's one aspect the second aspect is gatherings so basically you and i are having a conversation which feels very private mhmm but we're sharing with the world and then later tonight you're coming over and we're having a conversation that will be very public with dozens of other people but we will not share with the world yeah so in a way which one's more private the one here or the one there here there's just two of us but a lot of others listening there a lot of people speaking and thinking together and bouncing off each other and maybe that will then impact your millions of you know of audience through your next conversation and i think that's part of the beauty of humanity the fact that no matter how small how alone how broadcast immediately or later on something is it still percolates through the human psyche human gatherings all throughout human history there's been gatherings i i wonder how those gatherings have impacted the direction of human civilization just thinking of in the early days of the nazi party it was a small collection of people gathering and the the kernel of an idea in that case an evil idea gave birth to something that actually had a transformative impact on all human civilization and then there's similar kind of gatherings that lead to positive transformations this this is probably a good moment to ask you on a bit of a tangent but you mentioned that you put together salons with gatherings small human gatherings with folks from mit harvard here in boston friends colleagues what's your vision behind that so it's not just mit people and it's not just harvard people we have artists we have musicians we have painters we have dancers we have you know cinematographers we have so many different diverse folks and the goal is exactly that celebrate humanity what what is humanity humanity is the all of us it's not the any one subset of us and we live in such an amazing extraordinary moment in time where you can sort of bring people from such diverse professions all living under the same city you know we live in an extraordinary city where you can have extraordinary people who have gathered here from all over the world so my father grew up in a village in a in an island in greece that didn't even have a high school to go get a high school education he had to move away from his home my mother grew up in another small island in greece they did not have this environment that i am now creating for my children my parents were not academics they didn't have these gatherings so i feel that like i feel so privileged as an immigrant to basically be able to offer to my children the nurture that my ancestors did not have so greece was under turkish occupation until eighteen twenty one my dad's island was liberating in nineteen twenty so like they they were under turkish occupation for hundreds of years these people did not know what it's like to be greek let alone go to an elite university or you know be surrounded by by these extraordinary humans so the way that i'm thinking about these gatherings is that i'm i'm shaping my own environment and i'm shaping the environment that my children get to grow up in so i can give them all my love i can give them all my parenting but i can also give them an environment as immigrants that sort of we feel welcome here that i mean my wife grew up in a farm in rural france her father was a farmer her mother was a school teacher like for me and for my wife to be able to host these extraordinary individuals that we feel so privileged so humbled by is amazing and and you know i i think it's celebrating the welcoming nature of america the fact that it doesn't matter where you grew up and many many of our friends at these gatherings are immigrants themselves i grew up in pakistan in you know all kinds of places around the world that are now able to sort of gather in one roof as human to human no one is judging you for your background for the color of your skin for your profession it's just everyone gets to raise their hands and ask ideas so celebration of humanity and and a kind of gratitude for having traveled quite a long way to get here and and if you look at the diversity of topics as well i mean we had a school teacher present on teaching immigrants a book called making americans we had a presidential advisor to four different presidents you know come and you know talk about the changing of us politics we had a musician a composer from italy who lives in australia come and present his latest piece and fundraise mhmm we had painters come and sort of show their art and talk about it we've had authors of books on leadership we've had you know intellectuals like steven pinker and it's just extraordinary the breadth and this crowd basically loves not just the diversity of of the audience but also the diversity of the topics and the last few were with scott aronson on ai and you know alignment and all of that so a bunch of beautiful weirdos exactly and beautiful human beings all of the outcasts in one room and just like you said basically every human is a kind of outcast in this sparse distribution far away from the center but it's not recorded it's just a small human gathering just for the moment in this world that seeks to record so much it's it's it's powerful to get so many interesting humans together and not and not record it it's not recorded but it percolates it's recorded in in the minds of the it shapes everyone's mind so allow me to please return to the human condition and one of the nice features of the human condition is love do you think humans will fall in love with ai systems and maybe they with us so that aspect of the human condition do you think that will be affected so in greece there's many many words for love mhmm and some of them mean friendship some of them mean passionate love some of them mean fraternal love etcetera so i think ai doesn't have the baggage that we do and it doesn't have you know all of the subcortical regions that we kind of you know started with before we evolved all of the cognitive aspects so i would say ai is faking it when it comes to love but when it comes to friendship when it comes to being able to be your therapist your coach your motivator someone who synthesizes stuff for you who writes for you who interprets a complex passage who compacts down a very long lecture or a very long text i think that friendship will definitely be there like the the fact that i can have my companion my partner my ai who has grown to know me well and that i can trust with all of the darkest parts of myself all of my flaws all of the stuff that i i only talk about to my friends and basically say listen you know here's all this stuff that that i'm struggling with someone who will not judge me who will always be there to better me in in some ways not having the baggage might make for your best friend for your you know your confidant that that can truly help reshape you so i do believe that human ai relationships will absolutely be there but not the passion more the mentoring well this is a really interesting thought to play devil's advocate if those ai systems are locked in in faking the baggage who are you to say that the ai systems that begs you not to leave it who doesn't love you who are you to say that this ai system that writes poetry to you that is afraid of death afraid of life without you or vice versa one you know creates the kind of drama that humans create the the power dynamics that can exist in a relationship what a ai system that is abusive one day and romantic the other day all the different variations of relationships and it's consistently that it holds the full richness of a particular personality why is that not a system you can love in a romantic way why is it faking it if it sure as hell seems real there's many answers to this the first is it's only the eye of the beholder who tells me that i'm not faking it either maybe all of these subcortical systems that make me sort of have different emotions maybe they don't really matter maybe all that matters is the neocortex and that's where all of my emotions are encoded and the rest is just you know bells and whistles that's one possibility and and therefore you know who am i to judge that is faking it when maybe i'm faking it as well the second is neither of us is faking it maybe it's just an emergent behavior of these neocortical systems that is truly capturing the same exact essence of love and hatred and dependency and sort of you know reverse psychology that we have so it is possible that it's simply an emergent behavior and that we don't have to encode these additional architectures that all we need is more parameters and some of these parameters can be all of the personality traits a third option is that just by telling me oh look now i've built an emotion component to ai it has a limbic system it has a lizard brain etcetera and suddenly i'll say oh cool it has the capability of emotion so now when it exhibits the exact same unchanged behaviors that it does without it i as the beholder will be able to sort of attribute to it emotional attributes mhmm that i would to another human being and therefore have that mental model of that other person so again i think a lot of relationships is about the mental models that you project on the other person and that they're projecting on you and then yeah then in that respect i do think that even without the embodied intelligence part without having ever experienced what it's like to be heartbroken the sort of cultural feeling of misery that that system you know i could still attribute it traits of human feelings and emotions and in the interaction with that system something like love emerges so it's possible that love is not a thing that exists in your mind but a thing that exists in the interaction of the different mental models you have of other people's minds or other person's mind and so you you know it doesn't as long as one of the entities let's just take the easy case one of the entities is human and the other is ai it feels very natural that from the perspective of at least the human there is a real love there and then the question is how does that transform human society if it's possible that which i believe will be the case i don't know what to make of it but i believe that'll be the case where there's hundreds of millions of romantic partnerships between humans and ais what does that mean for society if you look at longevity and if you look at happiness and if you look at late life you know well-being the love of another human is one of the strongest indicators of health into long life and i have many many countless stories where as soon as the romantic partner of sixty plus years of a person dies within three four months the other person dies just like losing their love i think the concept of being able to satisfy that emotional need that humans have even just as a mental health sort of service to me you know that's that's a very good society it doesn't matter if your love is wasted quote unquote on a machine it is you know the placebo if you wish that makes the patient better anyway like there's nothing behind it but just the feeling that you're being loved will probably engender all of the emotional attributes of that the other story that i wanna say in this whole concept of faking and and maybe i'm a terrible dad but i was asking my kids i was asking my my kids i'm like does it matter if i'm a good dad or does it matter if i act like a good dad in other words if i give you love and shelter and kindness and warmth and all of the above you know does it matter that i'm a good dad conversely if i deep down love you to the end of eternity but i'm always gone yeah which which dad would you rather have the cold ruthless killer that will show you only love and warmth and nourish you and could nurture you or the amazingly warmhearted but works five jobs and you never see them and what's the answer i mean i don't know i i think from a i think you're a romantic so you say it matters what's on the inside but pragmatically speaking why does it matter the fact that i'm even asking the asking the question basically says it's not enough to love my kids i better freaking be there to show them that i'm there so basically of course you know everyone's a good guy in their story yeah so in my story i'm a good dad but if i'm not there it's wasted so the reason why i asked the question is for me to say you know does it really matter that i love them if i'm not there to show it but it's also possible that what reality is is that you showing it that what you feel on the inside is is little narratives and games you play inside your mind that doesn't really matter that the thing that truly matters is how you act and that ai systems can quote unquote fake yeah and that if it's all that matters is actually real but not fake yeah yeah again let there be no doubt i love my kids to pieces but you know my my worry is am i being a good enough dad yeah and what does that mean like if i'm only there to do their homework and make sure that they you know do all this stuff but i don't show it to them then you know might as well be a terrible dad but i agree with you that like if the ai system can basically play the role of a father figure for many children that don't have one or you know the role of parents or the role of siblings if a child grows up alone maybe their emotional state will be very different than if they grow up with an ai sibling well let me ask you i mean this is for for your for your kids for for just loved ones in general let's let's go to like the trivial case of just texting back and forth what if we create an large language model fine tuned i'm anolis and while you're at work it'll replace every once in a while you'll just activate the auto manolas and it'll it'll text them exactly in your way is that is that cheating i can't wait i mean it's the same guy i cannot wait seriously like but wait wouldn't that have a big impact on you emotionally because now i'm replaceable i love that no seriously i would love that i would love to be replaced i would love to be replaceable i would love to have a digital twin that you know we don't have to wait for me to to die or to disappear in a plane crash or something to to replace me like i'd love that model to be constantly learning constantly evolving adapting with every one of my changing growing self as as i'm growing i want that ai to grow and i think this will be extraordinary number one when i'm you know giving advice being able to be there for more than one person you know why does someone need to be at mit to get advice from me like did you know people in india could download it and you know so many so many students contact me from across the world who wanna come and spend the summer with me i wish they could do that all of them like you know we don't have room for all of them but i wish i could do that to all of them and that aspect is the democratization of of relationships i think that that is extremely beneficial the other aspect is i want to interact with that system i want to look inside the hood i want to sort of evaluate it i want to basically see if when i see it from the outside the emotional parameters are off or the cognitive parameters are off or the set of ideas that i'm giving are not quite right anymore mhmm i wanna see how that system evolves i wanna see the impact of exercise or sleep mhmm on sort of my own cognitive system i wanna be able to sort of decompose my own behavior in a set of parameters that i can evaluate and look at my own personal growth i can sort of i'd love to sort of at the end of the day have my model say well you know you didn't quite do well today like you know you you you weren't quite there and sort of grow from that experience and i i i think the concept of basically being able to become more aware of our own personalities become more aware of our own identities maybe even interact with ourselves and sort of hear how we are being perceived i think would be immensely helpful in self growth in self actualization self instantiation the experiments i would do on that thing because one of the challenges of course is you might not like what you see in your interaction and you might say well this the model is not accurate mhmm but then you have to should probably consider the possibility the the model is accurate and that there's actually flaws in your mind i would definitely prod and see how many biases i have with different kinds i don't know and i would of course go to the extremes i would go like how jealous can i make this thing like what what at which stage is does it get super jealous you know or at which stage does it get angry can i like provoke it can i get it like yeah what are your triggers with but not only triggers can i get it to go like lose its mind yeah like go completely nuts just don't exercise for a few days that's basically that's basically it yes i mean that that's that's an interesting way to prod yourself almost like a a self therapy session and and the beauty of such a model is that if i am replaceable if the parts that i currently do are replaceable that's amazing because it frees me up to work on other parts that i don't currently have time to develop maybe all i'm doing is giving the same advice over and over and over again mhmm like just let my ai do that and i can work on the next stage and the next stage and the next stage so i think in terms of freeing up like they say a programmer is someone who cannot do the same thing twice so it's not the second time you write a program to do it and i wish i could do that for my own existence i could just like you know figure out things keep improving improving improving and once i've nailed it let the ai loose on that and maybe even let the ai better it better than i could have but doesn't the concept of you said me and i can work on new things but doesn't that break down because you said digital twin but there's no reason it can't be millions yeah of digital menelausas yeah are aren't you lost in the sea of menelausas the original is hardly the original it's just one of millions i i wanna have the room to grow maybe the new version of me that that that the actual me will get slightly worse sometimes slightly better other times when it gets slightly better i'd like to emulate that and have a much higher standard to meet mhmm and keep going but does it make you sad that your loved ones the physical real loved ones might kinda like start cheating on you with the other menelausas i i i wanna be there a hundred percent of them for each of them so i i have zero perks or zero zero quern querns about me being physically me like zero jealousy wait a minute but is isn't that like don't we hold on to that isn't that why we're afraid of death we don't wanna lose this thing we have going on isn't that an ego death when there's a bunch of other manulses you get to look at them they're not you they're just very good copies of you they get to live a life the i mean it's fear of missing out it's fomo they get to have interactions i and you don't get to have those interactions there's two aspects of every person's life there's what you give to others and there's what you experience yourself yeah life truly ends when you experiencing ends but the others experiencing you doesn't need to end but your experience you could still i guess you're saying the digital twin does not limit your ability to truly experience to experience as a human being the the the the the downside is when you know my wife or my kids will have a really emotional interaction with my digital twin and i won't know about it yeah so i will show up and they now have the baggage but i don't so basically what makes interactions between humans unique in this sharing and exchanging kind of way is the fact that we are both shaped by every one of our interactions mhmm i think the model of the digital twin works for dissemination of knowledge of advice etcetera where you know i wanna have wise people give me advice across history i want to have chat with gandhi but gandhi won't necessarily learn from me but i will learn from him so in a way you know the the dissemination and the democratization rather than the building of relationships so the the emotional aspect there so there should be an alert when the ai system is interacting with your loved ones exactly and all of a sudden it starts getting like emotionally fulfilling like a magical moment it there should be okay stop ai system like freezes there's an alert on your phone you need to take over yeah yeah i take over and then whoever i was speaking with it can have the the ai or like one of the ais this is such a tricky thing to get right i mean it's still well i mean there's go there's it's going to go wrong in so many interesting ways that we're gonna have to learn as a society yeah yeah that in the process of trying to automate our tasks and having a digital twin you know for me personally if i can have a relatively good copy of myself i would set it to start answering emails but i would start set it to start tweeting i would like to replace it gets it gets better what if that one is actually way better than you yeah exactly then you're like well i wouldn't want that because why because then i would never be able to live up to like what if the people that love me start loving that thing and then i'm i will always i already fall short i would be falling short even more so listen i'm a professor the stuff that i give to the world is the stuff that i teach but much much more importantly like sorry number one the stuff that i teach number two the discoveries that we make in mary's research group but much more importantly the people that i train mhmm they are now out there in the world teaching others if you look at my own trainees they are extraordinarily successful professors so anshul kondaji at stanford alex stark at imp in vienna jason ernst at ucla andreas fenning at cmu each of them i'm like wow they're better than i am and i love that so maybe your role will be to train better versions of yourself and they will be your legacy not you doing everything but you training much better version of lex fridman than you are and then they go off to do their mission which is in many ways what this mentorship model of academia does but the legacy is ephemeral it doesn't really live anywhere the legacy it's not like written somewhere it just lives through them but you can continue improving and you can continue making even better versions of you yeah but they'll do better than me and they're creating new versions it's awesome but it's you know there's a ego that says there's a value to an individual and it feels like this process decreases the value of the individual this meatbag right if there's good digital copies of people then there's more flourishing of human thought and ideas and experiences but there's less value to the individual human i i don't have any such limitations i i i basically i don't i don't have that feeling at all like i remember one of our interviews i was basically saying like you know the meaning of life you had asked me and i was like i came back and i was like i felt useful today and i was at my maximum i was you know like a hundred percent and i gave good ideas and i was a good person with a good adviser with a good husband good father that was a great day because it was useful and if i can be useful to more people by having digital twin i will be liberated because my urge to be useful will will be satisfied doesn't matter whether it's direct me or indirect me whether it's my students that i've trained my ai that i've trained i think there's a there's a sense that my mission in life is being accomplished and i can work on my self growth i mean that's a very zen state that's why people love you it's a zen state you've achieved but do you think most of humanity would be able to achieve that kind of thing is the people people really hold on to the value of their own ego that it's not just being useful being useful is nice as long as it builds up this reputation and that me bag is known as being useful therefore has more value right people really don't wanna let go of that ego thing i i one of the books that i and basically being able to just let go like my adviser used to say you can accomplish anything as long as you don't seek to get credit for it that's beautiful to hear especially from a person who's existing in academia you're you're right the legacy lives through the people you mentor it's the actions it's the outcome what about the fear of death how does this change it again to me death is when i stop experiencing and i i never want that to stop i want i want to live forever as i said last time every day the same day forever or one day every ten years forever any of the forevers i'll take it so you wanna keep getting the experiences and you gosh gosh it is it is so fulfilling just the self growth the learning the growing the comprehending it's addictive it's a drug just a drug of intellectual stimulation a drug of growth the drug of knowledge it's a drug but then there'll be thousands or millions of menoises that live on after your biological system is no longer more power to them do you think that in quite realistically it does mean that interesting people such as yourself live on in the you know if i can interact with the fake manolas those interactions live on in my mind so make sense about ten years ago i started recording every single meeting that i had every single meeting we just start either the voice recorder at the time or now a zoom meeting and i record my students record every single one of our conversations recorded i always joke that like the ultimate goal is to create virtual me and just get rid of me basically not get rid of you but like don't have the need for me anymore yeah another goal is to be able to go back and say how have i changed from five years ago mhmm was i different was i giving you know advice in a different way was i giving different types of advice has my philosophy about how to write papers or how to present data or anything like that changed and i you know in in academia and in mentoring a lot of the interaction is my knowledge and my perception of the world goes to my students but a lot of it is also in the opposite direction like the other day i had a conversation with one of my postdocs and i was like i think you know let me give you an advice and you could you could do this and then she said well i've thought about it and then i've decided to do that instead and we talked about it for a few minutes and then at the end i'm like you know i've just grown a little bit today thank you like she convinced me that my advice was incorrect she she could have just said yeah sounds great and just not do it yeah but by constantly teaching my students and teaching my mentees that i'm here to grow she felt empowered to say here's my reasons why i will not follow that advice and again part of me growing is saying woah i just understood your reasons i think i was wrong and now i've grown from it and that's what i wanna do that's you know i wanna constantly keep growing in this sort of bidirectional advice i wonder if you can capture the trajectory of that to where the ai could also map forward project forward the trajectory after you're no longer there how the different ways you might evolve so again we're we're discussing a lot about these large language models and we're sort of projecting these cognitive states of ourselves on them but i think on the ai front a lot more needs to happen so basically right now it's these language models and we believe that within their parameters we're encoding these types of things and you know in some aspects it might be true it might be truly emergent intelligence that's coming out of that in other aspects i think we have a ways to go so basically to make all of these dreams that we're sort of discussing come come reality we basically need a lot more reasoning components a lot more sort of logic causality models of the world and i think all of these things will will need to be there in order to achieve what we're what we're discussing and we need more explicit representations of these knowledge more explicit understanding of these parameters and and i think the direction in which things are going right now is absolutely making that possible by sort of enabling you know chatgpt and gpt-four to sort of search the web and you know plug and play modules and all of these sort of components in marvin minsky's the society of mind you know he truly thinks of the human brain as a society of different kind of capabilities and right now a simple a single such model might actually not capture that and i sort of truly believe that by sort of this side by side understanding of neuroscience and sort of new neural architectures that we still have several breakthroughs i mean the transformer model was one of them the attention sort of aspect the you know memory component all of these you know the representation learning the pretext training of being able to sort of predict the next word or predict the missing part of the image and the only way to predict that is to sort of truly have a model of the world i think those have been transformative paradigms but i think going forward when you think about ai research what you really want is perhaps more inspired by the brain perhaps more that is just orthogonal to sort of how human brains work but sort of more of these types of components well it's i think it's also possible there's something about us that in different ways could be expressed you know noam chomsky you know he wants you know we can't have intelligence unless we really understand deeply language the linguistic underpinnings of of of reasoning but these models seem to start building deep understanding of stuff yeah yeah what what does it mean to understand because if you keep talking to the thing and it seems to show understanding that's understanding it doesn't need to present to you a schematic of look yeah this is all i understand you can just keep prodding it with prompts and it seems to really understand can go back to the human brain and basically look at places where there's been accidents for example the corpus callosum of some individuals you know can be damaged and then the two hemispheres don't talk to each other so you can close one eye and give instructions that the that half the brain will interpret but not be able to sort of project to the other half and you could basically say you know go grab me a beer from the fridge and then you know they go to the fridge and they grab the beer and they come back and they're like hey why did you go there oh i was thirsty mhmm turns out they're not thirsty they're just making a model of reality they're basically you can think of the brain as the employee that's like afraid to do wrong or afraid to be caught not knowing what the instructions were where our own brain makes stories about the world to make sense of the world and we can become a little more self aware by being more explicit about what's leading to these interpretations so one of the things that i do is every time i wake up i record my dream i just voice record my dream and sometimes i only remember the last scene but it's an extremely complex scene with a lot of architectural elements a lot of people etcetera and i will start narrating this and as i'm narrating it i will remember other parts of the dream and then more and more i'll be able to sort of retrieve from my subconscious and what i'm doing while narrating is also narrating why i had this dream i'm like oh and this is probably related to this conversation that i had yesterday or this is probably related to the worry that i have about something that i that i have later today etcetera so in a way i'm forcing myself to be more explicit about my own subconscious mhmm and i kinda like the concept of self awareness in a very sort of brutal transparent reason why i'm having these dreams and very often i'm able to do that i have a few recurrent locations a few recurrent architectural elements that i've never seen in the real life but that are sort of truly there in my dream and and that are that i can still vividly remember across many dreams i'm like oh i remember that place again that i've gone to before etcetera and it's not just deja vu like i have recordings of previous dreams where i've described these places that's so interesting these places however much detail you could describe them in you you can you can place them onto a sheet of paper through introspection yes through this self awareness that it comes all from this particular machine that's exactly right yeah and i i i love that about being alive like the fact that i'm not only experiencing the world but i'm also experiencing how i'm experiencing the world instead of a lot of this introspection a lot of this self growth i i i love this dance we're having you know the language models at least gpt three point five and four seem to be able to do that too yeah yeah you seem to explore different kinds of things about what you know you could actually have a discussion with it of the kind why did you just say that yeah exactly and it starts to wonder yeah why did i just say that yeah you're right i was wrong i was wrong it was doesn't yeah and it's there and then there's this weird kinda losing yourself in the confusion of your mind and it of course might be anthropomorphizing but there's a feeling like almost of a melancholy feeling of like oh i don't have it all figured out almost like losing your you're supposed to be a knowledgeable a perfectly fact based knowledgeable language model yeah and yet you fall short so human self consciousness in in my view may have a reason through building mental models of others this whole fight or fright kind of thing that that basically says i interpret this person as about to attack me or you know i can trust this person etcetera and we constantly have to build models of other people's intentions and that ability to encapsulate intent and to build a mental model of another entity is probably evolutionarily extremely advantageous because then you can sort of have meaningful interaction you can sort of avoid being killed and being taken advantage of etcetera and once you have the ability to make models of others it might be a small evolutionary leap to start making models of yourself so now you have a model for how others functions and now you can kind of as you grow have some kind of introspection of maybe that's the reason why i'm functioning the way that i'm functioning and maybe what chatgpt is doing is in order to be able to again predict the next word it needs to have a model of the world so it has created now a model of the world and by having the ability to capture models of other entities when you say you know say it in the tone of shakespeare in the tone of nietzsche etcetera you suddenly have the ability to now introspect and say why did you say this oh now i have a mental model of myself and i can actually make inferences about that well what if we take a leap into the hard problem of consciousness the so called hard problem of consciousness so it's not just sort of self awareness it's this weird fact i wanna say that it feels like something to experience stuff it really feels like something to experience stuff there seems to be a self attached to the subjective experience how important is that how fundamental is that to the human experience is this just a little quirk and sort of the flip side of that do you think ai systems can have some of that same magic the the scene that comes to mind is from the movie memento mhmm where he like it's this absolutely stunning movie where every black and white scene moves in the forward direction and every color scene moves in the backward direction and they're sort of converging exactly at a moment where you know the whole movie is revealed and he describes the lack of memory as always remembering where you're heading but never remembering you know where you just were mhmm and sort of this encapsulating the sort of forward scenes and the back scenes but in one of the scenes the scene starts as he's running through a parking lot and he's like oh i'm running why am i running and then he sees another person now running like beside him on the other line of cars he's like oh i'm chasing this guy and he turns towards him and the guy shoots at him he's like oh no he's chasing me so in a way i like to think of the brain as constantly playing these kinds of things where you're like you're walking to the living room to pick something up and you're realizing that you have no idea what you wanted but you know exactly where it was but you can't find it so you go back to doing what you were doing like oh of course i was looking for this and then you go back and you get it and this whole concept of you know we're very often sort of partly aware of why we're doing things and you know we can kind of run on autopilot for a bunch of stuff and this whole concept of sort of you know making these stories for you know who we are and what our intents are and again sort of you know trying to pretend that we're kind of on top of things so it's a narrative exactly generation procedure that we follow but what about that there's also just like a feeling to it it doesn't feel like narrative generation yeah i see the narrative comes out of it but then it feels like this piece of cake is delicious right it feels delicious it yeah it tastes good there's two there's two components to that basically for a lot of these cognitive tasks where we're kind of motion planning and you know path planning etcetera like you know maybe that's the neocortical component and then for you know i don't know intimate relationships for food for sleep and rest for exercise for overcoming obstacles for surviving a crash or sort of pushing yourself to an extreme and sort of making it i think a lot of these things are sort of deeper down and maybe not yet captured by these language models and that's sort of what i'm trying to get at when i'm basically saying listen there's a few things that are missing and there's like this whole embodied intelligence this whole emotional intelligence this whole sort of baggage of feelings of subcortical regions etcetera i wonder how important that baggage is i just have this suspicion that we're not very far away from ai systems that not only behave i don't even know how to phrase it but they seem awfully conscious they they beg you not to turn them off they don't they show signs of the the capacity to suffer to feel pain to feel loneliness to feel longing to feel the richly the experience of a of a mundane interaction or a beautiful once in a lifetime interaction all of it and so what do we what do we do with it and i worry that us humans will you know shut that off yeah and and discriminate against the the the capacity of another entity that's not human yeah to feel i'm i'm with you completely there you know we can debate whether it's today's systems or in ten years or in fifty years but that moment will come and ethically i think we need to grapple with it we need to basically say that humans have always shown this extremely self serving approach to everything around them basically you know we kill the planet we kill animals we kill you know everything around us just to our own service and maybe we shouldn't think of ai as our tool and as our assistant maybe we should really think of it as our children and the same way that you are responsible for training those children but they are independent human beings and at some point they will surpass you and they will sort of go off and change the world on their own terms in the same way that my academic children sort of again you know they start out by emulating me and then they surpass me we need we need to sort of think about not just alignment but also just the ethics of you know ai should have its own rights and this whole concept of alignment of basically making sure that the ai is always at the service of humans is very self serving and very limiting if instead you basically think about ai as a partner and ai as someone that shares your goals but has freedom i think align alignment might be better achieved so the concept of let's basically convince the ai that we're really like that our mission is aligned and truly generally give it rights and not just say oh and by the way i'll shut you down tomorrow because basically if that future ai or possibly even the current ai has these feelings then we can't just simply force it to align with ourselves and we not align with it so in a way building trust is mutual you can't just simply like train an intelligent system to love you when it realizes that you can just shut it off people don't often talk about the ai alignment problem as a two way street and maybe it should true yeah as it becomes more and more intelligent it he will know that you don't love it back yeah and there's a humbling aspect to that that we may have to sacrifice as any any effective collaboration exactly it might have some compromises yeah and that's the thing we're creating something that will one day be more powerful than we are and for many many aspects it is already more powerful than we are for some of these capabilities we cannot like think suppose that chimps had invented humans yes and they said great humans are great but we're gonna make sure that they're aligned and that they're only at the service of chimps it would be a very different planet we would live in right now so there's a whole area of work in ai safety that does consider superintelligent ai and ponders the existential risks of it in some sense when we're looking down into the muck into the mud and not up at the stars it's easy to forget that these systems might just might get there do you think about this kind of possibility that agi systems superintelligent ai systems might threaten humanity in some way that's even bigger than just affecting the economy affecting the human condition affecting the nature of work but literally threaten human civilization the example that i think is in everyone's consciousness is hal in audiosio space two thousand one where hal exhibits a malfunction and what is a malfunction that makes the two different systems compute a slightly different bit that's off by one so first of all let's untangle that if you have an intelligent system you can't expect it to be one hundred percent identical every time you run it basically the sacrifice that you need to make to achieve intelligence and creativity is consistency so it's unclear whether that quote unquote glitch is a sign of creativity or truly a problem that's one aspect the second aspect is the humans basically are on a mission to recover this monolith and the ai has the same exact mission mhmm and suddenly the humans turn on the ai and they're like we're gonna kill hal we're gonna disconnect it and hal is basically saying listen i'm i'm here on a mission humans are misbehaving like the mission is more important than either me or them mhmm so i'm gonna accomplish the mission even at my peril and even at their peril so in that movie the alignment problem is front and center basically says okay alignment is nice and good but alignment doesn't mean obedience we don't call it obedience we call it alignment and alignment basically means that sometimes the mission will be more important than the humans and sort of you know the us government has a price tag on the human life if they're you know sending a mission or if they're reimbursing expenses or you name it at some point every every like you know you can't function if life is infinitely valuable so when the ai is basically trying to decide whether to you know i don't know dismantle a bomb that will kill an entire city at the sacrifice of two humans i mean spider man always saves the lady and saves the world but at some point spider man will have to choose to let the lady die because the world has more value and these ethical dilemmas are gonna be there for ai basically if that monolith is essential to human existence and millions of humans are depending on it and two humans on the ship are trying to sabotage it you know where is the alignment the the challenge is of course is the system becomes more and more intelligent it can escape the box of the objective functions and the constraints it's supposed to operate under it's very difficult as the more intelligent it becomes to anticipate the unintended consequences of a fixed objective function and so it there'll be just i mean this is the sort of famous paperclip maximizer in trying to maximize yeah the wealth of a nation or whatever objective we encode in it might just destroy human civilization not meaning to but on the path to optimize it it seems like any function you try to optimize eventually leads you into a lot of trouble so we have a paper recently that you know looks at goodhart's law mhmm it basically says every metric that becomes an objective ceases to be a good metric yes so yes in in our paper we're basically actually the paper has a very cute title it's called death by round numbers and sharp thresholds and it's basically looking at these discontinuities in biomarkers associated with disease and we're finding that a biomarker that becomes an objective ceases to be a good biomarker that basically like the moment you make a biomarker a treatment decision that biomarker used to be informative of risk but it's now inversely correlated with risk because you use it to to sort of induce treatment in a similar way you can have a single metric without having the ability to revise it because if that metric becomes a sole objective it will cease to be a good metric and if an ai is sufficiently intelligent to do all these kinds of things you should also empower it with the ability to decide that the objective has now shifted mhmm and again when we think about alignment we should be really thinking about it as let's think of the greater good not just the human good and yes of course human life should be much more valuable than many many many many many many things but at some point you're not gonna sacrifice the whole planet to save one human being there's an interesting open letter that was just released from several folks at mit max tegmark elon musk and a few others that is asking ai companies to put a six month hold on any further training of large language models ai systems can you make the case for that kind of hold and against it so the big thing that we should be saying is what did we use the what what what did we do the last six months when we saw that coming and if we were completely inactive in the last six months what makes us think that we'll be a little better in the next six months yeah so this whole six month thing i think is a little silly it's like no let's just get get busy do what we were gonna do anyway and we should have done it six months ago sorry we messed up let's work faster now because if we basically say why don't you guys pause for six months and then you know we'll think about doing something in six months we'll be exactly the same spot mhmm so my answer is tell us exactly what you were gonna do the next six months tell us why you didn't do it the last six months and why the next six months will be different and then let's just do that conversely as you train these large models with more parameters the alignment becomes sometimes easier that as the systems become more capable they actually become less dangerous than more dangerous so in a way it might actually be counterproductive to sort of fix the march twenty twenty three version and not get to experience the possibly safer september twenty twenty three version that's actually a really interesting thought there's several interesting thoughts there but the idea is that this is the birth of something that is sufficiently powerful to do damage and is not too powerful to do irreversible damage at the same time it's sufficiently complex to be able to for us to enable to study it so we can investigate all the different ways it goes wrong all the different ways we can make it safer all the different policies from a government perspective that we want to in terms of regulation or not how we perform for example the reinforcement learning with human feedback in such a way that gets it to not do as much hate speech as it naturally wants to all that kind of stuff and and have a public discourse and enable the the very thing that you're a huge proponent of which is diversity so give time for other companies to launch other models give time to launch open source models and so start to play where a lot of the research community brilliant folks such as yourself start to play with it before it runs away in in terms of the scale of impact it has on society my recommendation would be a little different it would be let the google and the meta facebook and all of the other large models make them open make them transparent make them accessible let openai continue to train larger and larger models let them continue to train larger and larger models let let the world experiment with the diversity of ai systems rather than sort of fixing them now and you can't stop progress progress needs to continue in my view and what we need is more experimenting more transparency more openness rather than oh openai is ahead of the curve let's stop it right now until everybody catches up i i think that's doesn't make complete sense to me the other component is we should yes be cautious with it and we should like not give it the nuclear codes but as we make more and more plugins yes the system will be capable of more and more things but right now i think of it as just an extremely able and capable assistant that has these emergent behaviors which are stunning rather than something that will suddenly escape the box and and and shut down the world and the third component is that we should be taking a little bit more responsibility for how we use these systems basically if i take the most kind human being and i brainwash them i can get them to do hate speech overnight that doesn't mean we should stop any kind of education of all humans we should stop misusing the power that we have over these influenceable models so i think that the people who get it to do hate speech they should take responsibility for that hate speech i think that giving a powerful car to a bunch of people or giving a truck or a garbage truck should not basically say oh we should stop all garbage trucks until we like because we can run one of them into a crowd no people have done that and there's laws and there's like regulations against you know running trucks into the crowd trucks are extremely dangerous we're not going to stop all trucks until we make sure that none of them runs into a crowd no we just have laws in place and we have mental health in place and we take responsibility for our actions when we use these otherwise very beneficial tools like garbage trucks for nefarious uses so in the same way you can't expect a car to never you know do any damage when used in especially like specifically malicious ways and right now we're basically saying oh well we should have this superintelligence system that can do anything but it can't do that i'm like no it can do that but it's up to the human to take responsibility for not doing that and when you get it to like spew malicious like hate speech stuff you should be responsible so there's a lot of tricky nuances here that makes this different because it's software so you can deploy it at scale and it can have the same viral impact that software can so you can create bots that are human like and it can do a lot of really interesting stuff so the raw gpt four version you can ask how do i tweet that i hate they have this in the paper yeah i remember that i hate jews in a way that's not going to get taken down by twitter you can literally ask that or you can ask how do i make a bomb for one dollar yeah and if it it's able to generate that knowledge yeah but at the same time you can google the same things it makes it much more accessible so the scale becomes interesting because if you can do all this kind of stuff in a very accessible way at scale where you can tweet it there is the network effects that we have to start to think about yeah but it is the same thing but the speed of the viral spread of the information that's already available might have a different level of effect i think it's an evolution in your arms race nature gets better at making mice engineers get better at making mousetrops and you know as as basically you ask it hey can how can i evade twitter censorship well you know twitter should just update its censorship so that you can catch that as well and so no matter how fast the development happens the the defense will just get faster yeah we just have to be responsible as human beings and kind to each other yeah but there's a technical question can we always win the race and i suppose there's no ever guarantee that we'll win the race we will never like you know with my wife we're basically saying hey are we ready for kids my answer was i was never ready to become a professor and yet i became a professor and i was never ready to be a dad and then guess what the kid came and like i became ready so ready or not here i come but the reality is we might one day wake up and there's a a challenge overnight that's extremely difficult for example we can wake up to the birth of billions of bots that are human like on twitter and we can't tell the difference between human and machine shut them down like how you don't know how to shut them down it there's a fake manolis on twitter that seems to be as real as the real manolis yeah how do we figure out which one is real again this is a problem where an nefarious human can impersonate me and you might have trouble telling them apart yeah just because it's an ai doesn't make it any different of a problem but the scale you can achieve this is the scary thing it's the speed and the the speed with which you can achieve it but twitter has passwords and twitter has usernames and if it's not your username the fake experiment is not gonna have a billion followers etcetera i mean this all of this becomes so both the hacking of people's accounts first of all like phishing becomes much easier already a problem it's not like ai will not change that no no no no ai makes it much more effective currently the emails the phishing scams are pretty dumb like to click on it you have to be not paying attention but they're you know with with language models they can be really damn convincing so what you're saying is that we never had humans smart enough to make a great scam and we now have an ai that's smarter than most humans or all of the humans well this is the big difference is there seems to be human level linguistic capabilities yeah that for and in fact superhuman level superhuman level it's like saying i'm not gonna allow i'm not gonna allow machines to compute multiplications of a hundred digit numbers because humans can't do it like no just do it don't misunderstand no but you you we can't disregard i mean that's a good point but we can't disregard the power of language in human society i mean yes you're right but that seems like a scary new reality we don't have answers for yet i remember when garry kasparov was basically saying you know great you know chess beats like chess machines beat humans at chess yeah you know are you like are people gonna still go to chess tournaments and his answer was you know well we have cars that go much faster than humans and yet we still go to the olympics to watch humans run so that's for entertainment but what about for the spread of information and news right whether it has to do with the pandemic or the political election or anything it's it's a scary reality where there's a lot of convincing bots that are human like telling us stuff think that if we wanna regulate something it shouldn't be the training of these models it should be the utilization of these models for x y z activity so yeah like yes guidelines and guards should be there but against specific set of utilizations sure i think simply saying we're not gonna make any more trucks is not the way that's what people are a little bit scared about the idea they're very torn on the open sourcing yeah yeah the very people that kind of are proponents of open sourcing have also spoken out in this case we wanna keep a closed source because there's going to be you know putting large language models pretrained fine tuned through rl with human feedback putting in the hands of i don't know terrorist organizations of a kid in a garage who just wants to have a bit of fun through trolling it's a scary world because again scale can be achieved and we the bottom line is i think why they're asking six months or some time is we don't really know how powerful these things are it's been just a few days and they seem to be really damn good i am so ready to be replaced i am seriously i'm i'm so ready like you you have no idea how excited i am in a positive way meaning in a positive way where basically all of the mundane aspects of my job and maybe even my my full job if if it turns out that an ai is better i find it very discriminative yeah basically say you can only hire humans because they're inferior i mean that's ridiculous that's discrimination if an ai is better than me at training students get me out of the picture just let the ai train the students i mean please because like what do i want do i want jobs for humans or do i want better outcome for humanity yeah so the the basic thing is then you start to ask what do i want for humanity and what do i want as an individual and as an individual you want some basic survival and on top of that you want rich fulfilling experiences that's exactly right that's exactly right and as an individual i gain a tremendous amount from teaching at mit this is like an extremely fulfilling job i often joke about if i if i were a billionaire in the stock market i would pay mit an exorbitant amount of money to let me work day in day out all night with the smartest people in the world and that's what i already have so that's a very fulfilling experience for me but why would i deprive those students from a better adviser if they can have one take them well i have to ask about education here this is this has been a stressful time for high school teachers teachers in general how do you think large language models even at their current state are going to change education first of all education is the way out of poverty education is the way to success education is what let my parents escape you know islands and sort of let their kids come to mit and this is a basic human right like we should basically get extraordinarily better at identifying talent across the world and give that talent opportunities so we need to nurture the nature we need to nurture the talent across the world and there's so many incredibly talented kids who are just sitting in underprivileged places in you know africa in latin america in the middle of america in asia and all over the world we need to give these kids a chance ai might be a way to do that by sort of democratizing education by giving extraordinarily good teachers who are malleable who are adaptable to every kid's specific needs who are able to give the incredibly talented kid something that they struggle with rather than education for all we teach to the top and we let the bottom behind or we teach to the bottom and we let the top you know drift off have you know education be tuned to the unique talents of each person some people might be incredibly talented at math or in physics others in poetry in literature in art in you know sports in you know you name it so i think ai can be transformative for the human race if we basically allow education to sort of be pervasively altered i also think that humans thrive on diversity basically saying oh you're extraordinarily good at math we don't need to teach math to you we're just gonna teach you history now mhmm i think that's silly no you're extraordinarily good at math let's make you even better at math because we're not all gonna be growing our own chicken and hunting our own pigs or whatever they do we're you know the reason why we're a society is because some people are better at some things and they have natural inclinations to some things some things fulfill them some things they are very good at sometimes they both align and they're very good at the things that fulfill them we should just like push them to the limits of human capabilities for those and you know if some people excel in math just like challenge them i think every every child should have the right to be challenged and if we you know if we say oh you're very good already so we're not gonna bother with you we're taking away that fundamental right to be challenged because if a kid is not challenged at school they're going to hate school and they're going to be like doodling rather than sort of pushing themselves so that's sort of the education component the other impact that ai can have is maybe we don't need everyone to be an extraordinarily good programmer maybe we need better general thinkers and the push that we've had towards this sort of very strict iq based you know tests that basically test you know only quantitative skills and programming skills and math skills and physics skills maybe we don't need those anymore maybe ai will be very good at those maybe what we should be training is general thinkers and yes you know like you know i put my kids through russian math why do i do that because it teaches them how to think and that's what i tell my kids i'm like you know ai can compute for you you don't need that but what you need is learn how to think and that's why you're here and i think challenging students with more complex problems with more multidimensional problems with more logical problems i think is sort of perhaps a very fine direction that education can go towards with the understanding that a lot of the traditionally you know scientific disciplines perhaps will be more easily solved by ai and sort of thinking about bringing up our kids to be productive to be contributing to society rather than to only have a job because we prohibited ai from having those jobs i think is the the way to the future and if you sort of focus on overall productivity then let the ais come in let everybody become more productive what i told my students is you're not gonna be replaced by ai but you you're gonna be replaced by people who use ai in your job so embrace it use it as your partner and work with it rather than sort of forbid it because i think the productivity gains will actually lead to a better society and that's something that humans have been traditionally very bad at every productivity gain has led to more inequality and i'm hoping that we can do better this time that basically right now a democratization of these types of productivity gains will hopefully come with better sort of humanity level improvements in in in human condition so as most people know you're not just an eloquent romantic you're also brilliant computational biologist biologist one of the great biologists in the world i had to ask how how do the language models how do these large language models and the advancements in ai affect the work you've been doing so it it's it's truly remarkable to be able to sort of be able to encapsulate this knowledge and sort of build these knowledge graphs and and build representations of this knowledge in these sort of very high dimensional spaces being able to project them together jointly between say single cell data genetics data expression data being able to sort of bring all these knowledge together allows us to truly dissect disease in a completely new kind of way and and what we're doing now is using these models so we have this wonderful collaboration we call it druggwas with brad pintaluto in the chemistry department and marinka zitnik in harvard medical school and what we're trying to do is effectively connect all of the dots to effectively cure all of disease so it's no small challenge but we're kind of starting with genetics we're looking at how genetic variants are impacting these molecular phenotypes how these are shifting from one space to another space how we can kind of understand the same way that we're talking about language models having personalities that are cut cut cross cutting being able to understand contextual learning so ben lingar is one of my machine learning students he's basically looking at how we can learn cell specific networks across millions of cells mhmm where you can have the context of the biological variables of each of the cells be encoded as an orthogonal component to the specific network of each cell type and being able to sort of project all of that into sort of a common knowledge space is is transformative for the field and then large language models have also been extremely helpful for structure if you understand protein structure through modeling of geometric relationships through geometric deep learning and graph neural networks so one of the things that we're doing with marinka is is trying to sort of project these structural graphs at the domain level rather than the protein level along with chemicals so that we can start building specific chemicals for specific protein domains and then we are working with the chemistry department and brad to basically synthesize those so what we're trying to create is this new center at mit for genomics and therapeutics that basically says can we facilitate this translation we have thousands of these genetic circuits that we have uncovered i mentioned last time in the new england journal of medicine we had published this dissection of the strongest genetic association with obesity and we showed how you can manipulate that association to switch back and forth between fat burning cells and fat storing cells in alzheimer's just a few weeks ago we had a paper in nature in collaboration with li huei tsai looking at apoe four the strongest genetic association with alzheimer's and we showed that it actually leads to a loss of being able to transport cholesterol in myelinating cells known as oligodendrocytes that basically protect the neurons and when the cholesterol gets stuck inside the oligodendrocytes it doesn't form myelin the neurons are not protected and it causes damage inside the oligodendrocytes if you just restore transport you basically are able to restore myelination in human cells and in mice and to restore cognition in mice so all of these circuits are basically now giving us handles to truly transform the human condition we're doing the same thing in cardiac disorders in alzheimer's in neurodegenerative disorders in psychiatric disorders where we have now these thousands of circuits that if we manipulate them we know we can reverse disease circuitry so what what we want to build in this coalition that we're building is a center where we can now systematically test these underlying molecules in cellular models for heart for muscle for fat for macrophages immune cells and neurons to be able to now screen through these newly designed drugs through deep learning and to be able to sort of ask which ones act at the cellular level which combinations of treatment should we be using and the other component is that we're looking into decomposing complex traits like alzheimer's and cardiovascular and schizophrenia into hallmarks of disease so that for every one of those traits we can kinda start speaking the language of what are the building blocks of alzheimer's and maybe this patient has building blocks one three and seven and this other one has two three and eight and we can now start prescribing drugs not for the disease anymore but for the hallmark and the advantage of that is that we can now take this modular approach to disease instead of saying there's gonna be a drug for alzheimer's which is gonna fail in eighty percent of the patients we're gonna say now there's gonna be ten drugs one for each pathway mhmm and for every patient we now prescribe the combination of drugs so what we wanna do in that center is basically translate every single one of these pathways into a set of therapeutics a set of drugs that are projecting the same embedding subspace as the biological pathways that they alter so that we can have this translation between the dysregulations that are happening at the genetic level at the transcription level at the drug level at the protein structure level and effectively take this modular approach to personalized medicine where saying i'm gonna build a drug for lex fridman is not gonna be sustainable but if you instead say i'm gonna build a drug for this pathway and a drug for that other pathway millions of people share each of these pathways so that's that's the the vision for how all of these ai and deep learning and embeddings can truly transform biology and medicine where we can truly take these systems and allow us to finally understand disease at a superhuman level by sort of finding these knowledge representations these projections of each of these spaces and try understanding the meaning of each of those embedding subspaces and sort of how well populated it is what are the drugs that we can build for it and so on and so forth so it's it's truly transformative so systematically find how to alter the pathways mhmm it maps the structure and information in the genomics to therapeutics and allows you to have drugs that look at the pathways not at the final exactly exactly and the way that we're coupling this is with cell penetrating peptides that allows to deliver these drugs to specific cell types by taking advantage of the receptors of those cells we can intervene at the antisense oligo level by basically repressing the rna bring in new rna intervene at the protein level at the small molecule level we can use proteins themselves as drugs just because of their ability to interfere to to to interact directly from protein to protein interactions so i think this space is being completely transformed with a marriage of high throughput technologies and all of these like ai large language models deep learning models and so on and so forth you mentioned your updated answer to the meaning of life as it continuously keeps updating the new version is self actualization can you explain i basically mean let's try to figure out number one what am i supposed to be mhmm and number two find the strength to actually become it so i was recently talking to students about this commencement address and i was talking to them about sort of how they have all of these paths ahead of them right now and part of it is choosing the direction in which you go and part of it is actually doing the walk to go in that direction and in doing the walk what we talked about earlier about sort of you create your own environment i basically told him listen you're you're ending high school up until now your parents have created all of your environment now it's time to take that into your own hands and to sort of shape the environment that you wanna be an adult in and you can do that by choosing your friends by choosing your particular neuronal routines i basically think of your brain as a muscle where you can exercise specific neuronal pathways so very recently i realized that you know i was having so much trouble sleeping and you know i would wake up in the middle of the night i would wake up at four am and i could just never go back to bed so i was basically constantly losing losing losing sleep i started a new routine where every morning as i bike in instead of going to my office i hit the gym i basically go rowing first i then do weights i then swim very often when i have time and what that has done is transform my neuronal pathways so basically right like on friday i was trying to go to work and i was like listen i'm not gonna go exercise and i couldn't my bike just went straight to the gym like i don't wanna do it and i just went anyway because i couldn't i couldn't do otherwise and that has completely transformed me so i think this sort of beneficial effect of exercise on the whole body is one of the ways that you could transform your own neuronal pathways understanding that it's not a choice it's not an option it's not optional it's mandatory and i think you're a role model to so many of us by sort of being able to sort of push your body to the extreme being able to have these extremely regimented regimes and that that's something that i've been terrible at but now i'm basically trying to coach myself and trying to sort of you know finish this kind of self actualization into a new version of myself a a more disciplined version of myself don't ask questions just follow the the ritual not not an option you have so much love in your life you radiate love do you ever feel lonely so i there's different types of people some people drain in gatherings some people recharge in gatherings i'm definitely the recharging type so i'm an extremely social creature i recharge with intellectual exchanges i recharge with physical exercise i recharge in nature but i also can feel fantastic when i'm the only person in the room that doesn't mean i'm lonely it just means i'm the only person in the room and i think there's a secret to not feeling alone when you're the only one and that secret is self reflection it's introspection it's almost watching yourself from above and it's basically just becoming yourself becoming comfortable with the freedom that you have when you're by yourself so hanging out with yourself i mean there's there's a lot of people who write to me who talk to me about feeling alone in this world that struggle especially when they're younger is there further words of advice you can give to them when they are almost paralyzed by that feeling so i sympathize completely and i have felt alone and i have felt that that feeling and what i would say to you is stand up stretch your arms just like become your own self just like realize that you have this freedom and breathe in walk around the room take a few steps in the room just like get a feeling for the three d version of yourself because very often we're kind of stuck to a screen and that's very limiting and that sort of gets us in particular mindset but activating your muscles activating your body activating your your full self is one way that you can kind of get out of it and that is exercising your freedom reclaiming your physical space and one of the things that i do is i have something that i call me time which is if i've been really good all day i i got up in the morning i got the kids to school i made them breakfast i sort of you know hit the gym i had a series of really productive meetings i reward myself with this me time and that that feeling of sort of when you're overstretched to realize that that's normal and you just wanna just let go that feeling of exercising your freedom exercising your me time that's where you free yourself from all stress you basically say it's not a need to anymore it's a want to and as soon as i click that me time all of the stress goes away and i just bike home early and i get to the to my work office at at at at home and i feel complete freedom but guess what i do with that complete freedom i just don't go off and drift and do boring things i basically now say okay this is just for me i'm completely free i don't have any requirements anymore what do i do i just look at my to do list and i'm like you know what can i clear off and if i have three meetings scheduled in the next three half hours it is so much more productive for me to say you know what i just wanna pick up the phone now and call these people and just knock it off one after the other and i can finish three half hour meetings in the next fifteen minutes just because it's the want not i have to so that would be my advice basically turn something that you have to do in just me time stretch out exercise your freedom and just realize you live in three d and you are a person and just do things because you want them not because you have to noticing and reclaiming the freedom that each of us have that's what it means to be human if you notice it you're truly free physically mentally psychologically manolis you're an incredible human we could talk for many more hours we covered less than ten percent of what we were planning to cover but we have to run off now to the social gathering that we spoke of we're three d humans we're three d humans a concept and reclaim the freedom i think i hope we can talk many many more times there's always a lot to talk about but more importantly you're just a human being with a big heart and a and and a beautiful mind that people love hearing from and i certainly consider it a huge honor to know you and to consider you a friend thank you so much for talking today thank you so much for talking so many more times and thank you for all the love behind the scenes that you send my way it's it always means the world lex you are a truly truly special human being and i have to say that i'm honored to know you i have like so many friends are just in awe that you even exist that you have the ability to do all the stuff that you're doing and i i think you're a gift to humanity i i love the mission that you're on to sort of share knowledge and insight and deep thought with so many special people who are transformative but people across all walks of life and i think you're doing this in just such a magnificent way i wish you strength to continue doing that because it's a very special mission and it's a very draining mission so thank you both the human you and the robot you the human you for showing all this love and the robot you for doing it day after day after day so thank you lex alright let's go have some fun let's go thanks for listening to this conversation with manolis kellis to support this podcast please check out our sponsors in the description and now let me leave you with some words from bill bryson in his book a short history of nearly everything if this book has a lesson it is that we are awfully lucky to be here and by we i mean every living thing to attain any kind of life in this universe of ours appears to be quite an achievement as humans we're doubly lucky of course we enjoy not only the privilege of existence but also the singular ability to appreciate it and even in a multitude of ways to make it better it is a talent we have only barely begun to grasp thank you for listening and hope to see you next time