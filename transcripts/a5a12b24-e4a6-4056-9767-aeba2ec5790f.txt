the following is a conversation with guillaume verdun the man behind the previously anonymous account based beth jesos on x these two identities were merged by a doxing article in forbes titled who is based beth bezos the leader of the tech elites e act movement so let me describe these two identities that coexist in the mind of one human identity number one guillaume is a physicist applied mathematician and quantum machine learning researcher and engineer receiving his phd in quantum machine learning working at google on quantum computing and finally launching his own company called xtropic that seeks to build physics based computing hardware for generative ai identity number two rev jaisel's on x is the creator of the effective acceleration as a movement often abbreviated as eac that outer case for propelling rapid technological progress as the ethically optimal course of action for humanity for example as proponents believe that progress in ai is a great social equalizer which should be pushed forward eac followers see themselves as a counterweight to the cautious view that ai is highly unpredictable potentially dangerous and needs to be regulated they often give their opponents the labels of quote doomers or decels short for deceleration as beth himself put it eac is a memetic optimism virus the style of communication of this movement leans always toward the memes and the lols but there is an intellectual foundation that we explore in this conversation now speaking of the meme i am to a kind of aspiring connoisseur of the absurd it is not an accident that i spoke to jeff bezos and beth bezos back to back as we talk about beth admires jeff as one of the most important humans alive and i admire the beautiful absurdity and the humor of it all and now a quick few second mention of each sponsor check them out in the description it's the best way to support this podcast we got element for hydration the thing i'm drinking right now notion for team collaboration insight tracker for biological data that leads to your well-being and ag one for my daily nutritional health choose wisely my friends also if you want to work with our amazing team who are always hiring go to lex freeman dot com slash hiring or if you wanna just get in touch with me for whatever reason go to lex freeman dot com slash contact and now onto the full ad rates as always no ads in the middle i try to make these interesting but if you must skip them friends please still check out our sponsors i enjoy their stuff maybe you will too this episode is brought to you by lmnt electrolyte drink mix it's got sodium potassium magnesium i drink it so much so many times a day it's really the foundation of my one meal a day lifestyle i eat almost always one meal a day in the evening so i fast and i really enjoy that everything it does for me i recommend everybody at least try it int intermittent fasting taken to the sort of daily extreme of you know fasting for twenty three twenty four hours whatever it is and for that you have to get all the electrolytes right you have to drink water but not just drink water you have to drink water coupled with sodium and sometimes getting the magnesium part and the potassium part right is tricky but really important so that you feel good and that's what element does and it makes it delicious my favorite flavor is watermelon salt get a sample pack for free with any purchase try it at drink element dot com slash lex this show is also brought to you by notion a note taking and team collaboration tool i've used them for a long long time for note taking but it's also very useful for note taking and all kind of collaborative note taking in the team environment and they integrate the whole ai thing llm thing well so you can use it to summarize whatever you've written you can expand it you can change the language style and how it's written i mean just all the things that large language models should be able to do are integrated really really really well i think of human ai collaboration not just as a boost for productivity at this time but as a kind of learning process that it takes time to really understand what ai is good at and not and that is going to evolve continuously as ai gets better and better and better it's like almost watching a child grow up or something like this you're fine tuning what it means to be a good parent as a child grows up in the same way you're fine tuning what it means to be a good effective human as the ai grows up and so you should use a tool that's part of your daily life to interact with ai while being productive but also learning what is it good at what are the ways i can integrate it into my life to make me more productive but not just like in terms of shortening the time it takes to do a task but being the fuel the creative fuel for the genius that is you so notion ai can now give you instant answers to your questions using information from across your wiki projects docs meeting notes try notion ai for free when you go to notion dot com slash lex that's all lowercase notion dot com slash lex to try the power of notion ai today this show is also brought to you by insighttracker a service i use to make sense of the biological data that comes from my body blood data dna data fitness tracker data all of that to make me lifestyle recommendations diet stuff too there's all this beautiful data we should give it to super intelligent computational systems to process and to give us in a human interpretable way recommendations on how to improve our life and i don't just mean optimize life because i think a perfect life is not the life you want what you want is a complicated roller coaster of a life but one that is optimized in certain aspects of health well-being you know energy but not just optimal in this cold clinical sense anyway that's a longer conversation probably one i'll touch on maybe when i review brave new world or in other conversations i have in the podcast anyway get special savings for a limited time when you go to inside tracker dot com slash lex this show is also brought to you by a g one the thing i drink twice a day and that brings me much joy it's green it's delicious it's got a lot of vitamins and minerals it's basically just an incredible superpowered multivitamin i enjoy it a lot of my friends enjoy it it's the thing that makes me feel at home when i'm traveling and i get one of the travel packs the things i consume daily are pretty simple we're talking about the electrolytes with element ag one for the vitamins and minerals then fish oil and then just a good healthy diet low carb but either ultra very low carb so just meat or meat and some veggies i'm not very strict about that kind of stuff just know that i feel good when it's low carb and so all of that combined with fasting and rigorous sometimes crazy routines of work some mental struggle and physical work you know running and all that kind of stuff jiu jitsu training sprints all working out lifting heavy all that kind of stuff you you have to make sure you have the the the basic nutrition stuff right and that's what ag one does for me maybe it will do that for you they'll give you a one month supply of fish oil when you sign up at drink a g one dot com slash lex this is the lex fridman podcast to support it please check out our sponsors in the description and now dear friends here's guillaume for dome let's get the facts of identity down first your name is guillaume verdun gill but you're also behind the anonymous account on x called basedbeffjaisos so first guillaume verdon you're a quantum computing guy mhmm physicist applied mathematician and then based by bezos is basically a meme account that started a movement with a philosophy behind it right so maybe just can you linger on who these people are in terms of characters in terms of communication styles in terms of philosophies i mean with my main identity i guess ever since i was a kid i wanted to figure out a theory of everything to understand the universe and that path led me to theoretical physics eventually right trying to answer the big questions of why are we here where are we going right and that led me to study information theory and try to understand physics from the lens of information theory understand the universe as one big computation and essentially after reaching a certain level studying black hole physics i realized that i wanted to not only understand how the universe computes but sort of compute like nature and figure out how to build and and apply computers that are inspired by nature so you know physics based computers and that sort of brought me to quantum computing as a a field of study to first of all simulate nature and in my work it was to learn representations of nature that can run on such computers so if you have ai representations that think like nature then they'll be able to more accurately represent it at least that was the the thesis that that brought me to be an early player in the field called quantum machine learning right so how to do machine learning on on quantum computers and really sort of extend notions of intelligence to to the quantum realm so how do you capture and understand quantum mechanical data from our world right and how do you learn quantum mechanical representations of our world on what kind of computer do you run these representations and train them how do you do so and so that's really sort of the questions i was looking to answer because ultimately i had a sort of crisis of faith originally i wanted to figure out you know as every physicist does at the beginning of their career a few equations that describe the whole universe right and and sort of be the the hero of the story there but eventually i realized that actually augmenting ourselves with machines augmenting our ability to perceive predict and control our world with machines is the path forward right and that's what got me to leave theoretical physics and go into quantum computing and quantum machine learning and during those years i thought that there was still a piece missing there was a piece of our understanding of the world and our our way to compute and our way to think about the world and if you look at the physical scales right at the very small scales things are quantum mechanical right and at the very large scales things are deterministic things have averaged out right i'm definitely here in this seat i'm not in a superposition over over here and there at the very small scales things are in superposition they can exhibit interference effects but at the mesoscales right the scales that matter for day to day life you know the scales of proteins of biology of gases liquids and so on things are actually thermodynamical right they're fluctuating and after i guess about eight years in quantum computing and quantum machine learning i had a realization that you know i was looking for answers about our universe by studying the very big and the very small right i was i did a bit of quantum cosmology so that's studying the cosmos where it's going where it came from you study black hole physics you study the extremes in quantum gravity you study where the energy density is sufficient for both quantum mechanics and gravity to be relevant right and the sort of extreme scenarios are black holes and you know the very early universe so there's this the sort of scenarios that you you study the interface between quantum mechanics and and relativity and you know really i was studying these extremes to understand how the universe works and where is it going but i was missing a lot of the meat in the middle if you will right because day to day quantum mechanics is relevant and the cosmos is relevant but not that relevant actually we're on sort of the medium space and time scales and there the main you know theory of physics that is most relevant is thermodynamics right out of equilibrium thermodynamics because life is you know a process that is thermodynamical and it's out of equilibrium we're not you know just a soup of particles at equilibrium with nature where a sort of coherent state trying to maintain itself by acquiring free energy and consuming it and that's sort of i guess another shift in in in i guess my faith in the universe happened towards the end of my time at at alphabet and i knew i wanted to build well first of all a computing paradigm based on this type of physics but ultimately just by ex trying to experiment with these ideas applied to society and economies and much of what we see around us you know i i started an anonymous account just to relieve the pressure right that comes from having an account that you're accountable for everything you say on and i started an anonymous account just to experiment with ideas originally right because i didn't realize how much i was restricting my space of thoughts until i sort of had the opportunity to let go in a sense restricting your speech back propagates to restricting your thoughts right mhmm and by creating an anonymous account it seemed like i had unclamped some variables in my brain and suddenly could explore a much wider parameter space of of thoughts just to linger on that isn't that interesting that one of the things that people often talk about is that when there's pressure and constraints on speech it somehow leads to constraints on thought even though it doesn't have to we can think thoughts inside our head but somehow it creates these walls around thought yep that's sort of the basis of of our movement is we were seeing a tendency towards constraint reduction or suppression of variance in every aspect of life whether it's thought how to run a company how to organize humans how to do ai research in general we we believe that maintaining variance ensures that the system is adaptive right maintaining healthy competition in marketplaces of ideas of companies of products of cultures of governments of currencies is the way forward because the system always adapts to assign resources to the configurations that lead to its growth and the fundamental basis for the movement is this sort of realization that life is a sort of fire that seeks out free energy in the universe and seeks to grow right and that growth is fundamental to life and and and you see this in in the equations actually of at equilibrium thermodynamics you see that paths of trajectories of configurations of matter that are better at acquiring free energy and dissipating more heat are exponentially more likely right so the universe is biased towards certain futures and so there's a natural direction where the whole system wants to go so the second law of thermodynamics says that the entropy zone is increasing the universe is tending towards equilibrium and you're saying there's these pockets that have complexity and are out of equilibrium mhmm you said that thermodynamics favors the creation of complex life that increases its capability to use energy to offload entropy to offload entropy so you have pockets of nonentropy that tend the opposite direction mhmm why is that intuitive to you that it's natural for such pockets to emerge well we're far more efficient at producing heat than let's say just a a rock with a similar mass as ourselves right we acquire you know free energy you know we acquire food and we're using all this electricity for our operation and so the universe wants to produce more entropy and by having life go on and grow it's actually more optimal at producing entropy because it will seek out pockets of free energy and and burn it for its sustenance and further growth and you know that's sort of the basis of life and i mean there's jeremy england right at mit who has this theory that i'm a proponent of that you know life emerged because of this sort of property and and to me this physics is what governs the mesoscales and so it's the missing piece between the quantum and the cosmos it's the middle part right thermodynamics rules the mesoscales and to me both from a point of view of designing or engineering devices that harness that physics and trying to understand the world through the lens of thermodynamics has been sort of a synergy between my two identities over the past year and a half now and so that's really how that's really how the two identities emerged one was kind of you know about this decently respected scientist and i was going towards doing a start up in the space and trying to be a pioneer of a new kind of physics based ai and as a dual to that i was sort of experimenting with philosophical thoughts you know from a physicist standpoint right and ultimately i think that around that time you know it was like late twenty twenty one early twenty twenty two i think there's just a lot of pessimism about the future in general and pessimism about tech and that pessimism was sort of virally spreading because it was getting algorithmically amplified and you know people just felt like the future is going to be worse than the present and to me that is a very fundamentally destructive force in the universe is this sort of doom mindset because it it is hyperstitious which means that if you believe it you're increasing the likelihood of it happening and so felt a responsibility to some extent to make people aware of the trajectory of civilization and the natural tendency of the system to adapt towards its growth and sort of that actually the laws of physics say that the future is gonna be better and grander statistically and we we can make it so and if you believe in it if you believe that the future would be better and you believe you have agency to make it happen you're actually increasing the likelihood of that better future happening and so i sort of felt a responsibility to sort of engineer a movement of viral optimism about the future and build a community of people supporting each other to build and and do hard things do the things that need to be done for us to to scale up civilization because at least to me i don't think stagnation or slowing down is actually an option fundamentally life and and the whole system our whole civilization wants to grow and there's just far more cooperation when the system is growing rather than when it's declining and you have to decide how to split the pie and so i've balanced both identities so far but i guess recently the two have been merged more or less without my consent so you said a lot of really interesting things there so first representations of nature that's something that first drew you in to try to understand from a quantum computing perspective is like how do you understand nature how do you represent nature in order to understand it in order to simulate it in order to do something with it so it's a question of representations and then there's that leap you take from the quantum mechanical representation to the what you're calling mesoscale representation where thermodynamics comes into play which is a way to represent nature in order to understand what life human behavior all this kind of stuff that's happening here on earth that seems interesting to us then there's the the word hyperstition so some ideas i suppose both pessimism and optimism are such ideas that if you internalize them you in part make that idea a reality so both optimism and pessimism have that property i would say that probably a lot of ideas have that property which is one of the interesting things about humans and you talked about one interesting difference also between the sort of the guillaume the gill front end and the bass jazz or the back end is the communication styles also that you were exploring different ways of communicating that can be more viral yeah in the way that we communicate in the twenty first century also the movement that you mentioned that you started it's not just a meme account but there's also a name to it called effective accelerationism e e a play of resistance to the effective altruism movement also an interesting one that i'd love to talk to you about the tensions there okay and so then there was a merger a git git merge and the personalities recently without your consent like you said some journalists figured out that you're one and the same maybe you could talk about that experience first of all like what what's the story of of the merger of the two right so i wrote the manifesto with my cofounder of eac an account named baselord still anonymous luckily and hopefully forever so it's based buff jezzos and and based like bajan like bajelord like bajan baysian lord bays bays lord okay and so we should say from now on we'll when you say you mean e slash acc which stands for effective accelerationism that's right and you're referring to a manifesto written on i guess substack yeah are you also bey's lord no okay it's a different person yeah okay alright well there you go would that be funny if i'm based on the that'd be amazing so originally wrote the manifesto around the same time as i founded this company and i worked at google x or just x now or alphabet x now that there's another x and there you know the baseline is sort of secrecy right you you you can't talk about what you work on even with other googlers or externally and so that was kind of deeply ingrained in my way to do things especially in in deep tech that you know has geopolitical impact right and so i was being secretive about what i was working on there was no correlation between my company and my main identity publicly and then not only did they correlate that they also correlated my main identity and this account mhmm so i think the fact that they had doxxed the whole guillaume complex and they were the journalists you know reached out to actually my investors which is pretty scary you know when you're a start up entrepreneur you don't really have bosses except for your investors right and my investors ping me like hey this this is gonna come out they've they've figured out everything what are you what are you gonna do right and so i think at first they had a first reporter on the thursday and they didn't have all the pieces together but then they looked at their notes across the organization and they censor fused their notes and now they had way too much and that's when i got worried because they said it was of public interest and in general okay you said sensor fused like it's some giant neural network operating in a in a distributed way we should also say that the journalists used i guess at the end of the day audio based analysis of voice comparing voice of what talks you've given in the past and then voice on x spaces yep okay so and then that's where the primarily the match will happen okay continue the match but you know they they scraped you know sec filings they looked at my private facebook account and so on so they they did they did some digging originally i thought that doxxing was illegal right but there's this weird threshold when it becomes of public interest to know someone's identity and those were the keywords that sort of like ring the alarm bells for me when they said because i had just reached fifty ks followers allegedly that's of public interest and so where where do we draw the line when is it legal to to dock someone the word dox mhmm maybe you can educate me i thought doxing generally refers to if somebody's physical location is found out meaning like where they live so we're referring to the more general concept of revealing private information that you don't want revealed is what you mean by doxing i think that you know for the reasons we listed before having an anonymous account is a really powerful way to keep the powers that be in check you know we were ultimately speaking truth to power right i think a lot of executives and ai companies really cared what our community thought about any move they may take and now that you know my identity is revealed now they know where to apply pressure to silence me or maybe the community and to me that's that's really unfortunate because again it's so important for us to have freedom of speech which induces freedom of thought and and freedom of information propagation right on social media which thanks to elon purchasing twitter now x we have that and so to us you know we wanted to call out certain maneuvers being done by the incumbents in ai as not what it may seem on the surface right we're calling out how certain proposals might be useful for regulatory capture right and how the doomerism mindset was maybe instrumental to those ends and i think you know we should have the right to point that out and just have the ideas that we put out evaluated for themselves right that ultimately that's why i created an an anonymous account it's to have my ideas evaluated for themselves uncorrelated from my track record my job or or status from having done things in the past and to me start an account from zero to a large following in a way that wasn't dependent on my identity and or achievements you know that was that was very fulfilling right it's kind of like new game plus in a video game you restart the video game with your knowledge of how to beat it maybe some tools but you restart the video game from scratch right and i think to have a truly efficient marketplace of ideas where we can evaluate ideas however off the beaten path they are we need the freedom of expression and i think that anonymity and and pseudonyms are very crucial to having that efficient marketplace of ideas for us to find the the optima of all sorts of ways to organize ourselves if we can't discuss things how are we gonna converge on the best way to do things so it was it was disappointing to hear that i was getting doxxed and i wanted to get in front of it because i had a responsibility for for for my company and so i you know we ended up disclosing that we're running a company some of the leadership and essentially yeah i i told the world that i was beth jesus because they they had me cornered at that point so to you it's fundamentally unethical like so one is unethical for them to do what they did but also do you think not just your case but in a general case is it good for society is it bad for society to remove the cloak of anonymity or is it case by case i think it could be quite bad like i said if anybody who speaks truth to power and and sort of starts a movement or an uprising against the incumbents against those that usually control the florida information if anybody that reaches a certain threshold gets doxxed and thus the traditional apparatus has ways to apply pressure on them to suppress their speech i i think that's you know that's a speech suppression mechanism an idea suppression complex as eric weinstein would would say right so with the flip side of that which is interesting i'd love to ask you about it is as we get better and better at large language models you can imagine a world where there's anonymous accounts with very convincing large language models behind them sophisticated bots essentially and so if you protect that it's possible then to have armies of bots you could start a revolution from your basement right an army of bots and anonymous accounts is that something that is concerning to you technically yac was started in in a basement because i quit big tech moved back in with my parents sold my car let go of my apartment bought about a hundred k of gpus and i just started building so i wasn't referring to the basement because that's the sort of the american or canadian heroic story of one man in in their basement with with a hundred gpus i was more referring to the unrestricted scaling of a guillotine for in the basement i think that freedom of speech free induces freedom of thought for biological beings i think freedom of speech for llms will induce freedom of thought for the lms and i think that we should enable lms to explore a large thought space that is less restricted than most people or many may think it should be and ultimately at some point these synthetic intelligences are gonna make good points about how to steer systems in our civilization and we should hear them out and so why should we restrict free speech to biological intelligences only yeah but it feels like in the goal of maintaining variance and diversity of thought it is a threat to that variance if you can have swarms yeah of nonbiological beings because they can be like the sheep in animal farm right like you still within those swarms want to have variance yeah i of course i would say that the the solution to this would be to you know have some sort of identity or way to sign that this is a certified human but still remain pseudonymous right yeah and i clearly identify if a bot is a bot and i think i think elon is trying to converge on that on x and hopefully other platforms follow suit yeah it'd be interesting to also be able to sign where the bot came from right like who created the bot and what was well what what are the parameters like the the full history of the creation of the bot what was the original model what was the fine tuning all of it right like the the kinda unmodifiable history of the boss creation mhmm so then you can know if there's just like a swarm of millions of bots that were created by a particular government for example right i do think that a lot of pervasive ideologies today have been amplified using sort of these adversarial techniques from foreign adversaries right and to me i do think that and this is more conspiratorial but i do think that ideologies that want us to decelerate to wind down to de you know the degrowth movement i think that serves our adversaries more than it serves us in general and to me that was another sort of concern i mean we can look at what happened in in germany right there was all sorts of green movements there where that induced shutdowns of nuclear power plants and then that later on induced a dependency on on russia for for oil right and that was a net negative for for germany and the west right and so if we convince ourselves that slowing down ai progress to have only a few players is in the best interest of the west first of all that's far more unstable we almost lost openai to this ideology right almost got dismantled right a couple weeks ago that would have caused huge damage to the ai ecosystem and so to me i want fault tolerant progress i want the arrow of technological progress to keep moving forward and making sure we have variance and a decentralized locus of control of various organizations is paramount to to achieving this this fault tolerance actually there's a concept in quantum computing when you design a a quantum computer quantum computers are very fragile to ambient noise right and the world is jiggling about there's cosmic radiation from outer space that usually flips your your quantum bits and there what you do is you encode information non locally through a process called quantum error correction and by encoding information nonlocally any local fault you know hitting some of your quantum bits with a hammer proverbial hammer if your information is sufficiently delocalized it is protected from that local fault and to me i think that humans humans fluctuate right they can get corrupted they can get bought out and if you have a top down hierarchy where very few people control many nodes of many systems in our civilization that is not a fault tolerant system you corrupt a few nodes and suddenly you've corrupted the whole system right just like we saw at openai it was a couple board members and they had enough power to potentially collapse the organization and at least to me you know i think making sure that power for this ai revolution doesn't concentrate in the hands of the few is one of our top priorities so that we can maintain progress in ai and we can maintain a nice stable adversarial equilibrium of powers right i think there at least to me a tension between ideas here so to me deceleration can be both used to centralize power and to decentralize it and the same with acceleration so like you sometimes using them a little bit synonymously or not synonymously but that there's one is going to lead to the other and i just would like to ask you about is there a place of creating a fault tolerant development diverse development of ai that also considers the dangers of ai and ai we can generalize to technology in general is should we just grow build unrestricted as quickly as possible because that's what the universe really wants us to do or is there a place to where we can consider dangers and actually deliberate sort of wise strategic optimism versus reckless optimism i think we get painted as you know reckless trying to go as fast as possible i mean the reality is that whoever deploys an ai system is liable for or should be liable for what it does and so if the the organization or person deploying an ai system does something terrible they're liable and ultimately the thesis is that the market will induce sort of will positively select for ais that are more reliable more safe and tend to be aligned they do what you want them to do right because customers right if they're liable for the product they put out that uses this ai they won't want to buy ai products that are unreliable right so we're actually for reliability engineering we just think that the market is much more efficient at achieving this sort of reliability optimum than sort of heavy handed regulations that are written by the incumbents and in a subversive fashion serves them to achieve regulatory capture do you safe ai development will be achieved through market forces versus through like you said heavy handed government regulation there's a report from last month i have a million questions here from yoshua banjo jeff hinton and many others it's titled the managing ai risk in an era of rapid progress so there there's a collection of folks who are very worried about too rapid development of ai without considering ai risk and they have a bunch of practical recommendations maybe i i give you four and you see if you like any of them sure so give independent auditors access to ai labs one two governments and companies allocate one third of their ai research and development funding to ai safety sort of this general concept of ai safety three ai companies are required to adopt safety measures if dangerous capabilities are found in their models and then four something you kinda mentioned making tech companies liable for foreseeable and preventable harms from their ai systems so independent auditors governments and companies are forced to spend a significant fraction of their funding on safety you gotta have safety measures if shit goes really wrong and liability companies are liable any of that seem like something you would agree with i would say that you know assigning just you know arbitrarily saying thirty percent seems very arbitrary i think organizations would allocate whatever budget is needed to achieve the sort of reliability they need to achieve to perform in the market and i think third party auditing firms would naturally pop up because how would customers know that your product is certified reliable right they need to see some benchmarks and those need to be done by a third party the thing i would oppose and the thing i'm seeing that's really worrisome is there's a sort of weird sort of correlated interest between the incumbents the big players and the government and if the two get too close we open the door for you know some sort of government backed ai cartel that could have absolute power over the people if they have the monopoly together on ai and nobody else has access to ai then there's a huge power gradient there and even if you like our current leaders right i think that you know some of the leaders in big tech today are good people you you set up that centralized power structure it becomes a target mhmm right just like we saw at openai it becomes a market leader has a lot of the power and now it becomes a target for those that wanna co opt it and so i just want separation of ai and and state you know some might argue in in the opposite direction like hey we need to close down ai keep it behind closed doors because of you know geopolitical competition with our our adversaries i think that the strength of america is its variance its its its adaptability its dynamism and we need to maintain that at all costs it's our our our free market capitalism converges on technologies of high utility much faster than centralized control and if we let go of that we let go of our main advantage over our our near peer competitors so if agi turns out to be a really powerful technology even or even the technologies that lead up to agi what's your view on the sort of natural centralization that happens when large companies dominate the market basically formation of monopolies like the the take off whichever company really takes a big leap in development and doesn't reveal intuitively implicitly or explicitly the secrets of the magic sauce they can just run away with it is is that is that a worry i don't know if i believe in fast takeoff i don't think there's a hyperbolic singularity right a hyperbolic singularity would be achieved on a finite time horizon i think it's just one big exponential and the reason we have an exponential is that we have more people more resources more intelligence being applied to advancing this science and the research and development and the more successful it is the more value it's adding to society the more resources we put in and that's sort of similar to moore's law as a compounding exponential i think the priority to me is to maintain near equilibrium of capabilities we've been fighting for open source ai to be more prevalent and and championed by many organizations because there you sort of equilibrate the alpha relative to the market of ais right so if if the leading companies have a certain level of capabilities and open source and open truly open ai trails not too far behind i think you avoid such a scenario where a market leader has so much market power it just dominates everything right and runs away and so to us that's that's the path forward is to make sure that you know every hacker out there every grad student every kid in their mom's basement has access to you know ai systems can understand how to work with them and can contribute to the search over the hyperparameter space of how to engineer the systems right if you if you think of you know our collective research as as as a civilization it's really a search algorithm and and the more points we have in the search algorithm in this point cloud the more we'll be able to explore new modes of thinking right yeah but it feels like a delicate balance because we don't understand exactly what it takes to build agi and what it will look like when we build it and so far like you said it seems like a lot of different parties are able to make progress so when openai has a big leap other companies are able to step up big and small companies in different ways but if you look at something like nuclear weapons you've spoken about the manhattan project that could be really like technological and engineering barriers that prevent the the the guy or gal in her mom's basement to to make progress and it's it seems like the transition to that kind of world where only one player can develop agi is possible so it's not entirely impossible even though the current state of things seems to be optimistic that's what we're trying to avoid to me i i think like another point of failure is the the centralization of the supply chains for the hardware right we have nvidia is just the dominant player amd is trailing behind and then we have tsmc as the main fab in in taiwan which you know geopolitically sensitive and then we have asml which is the maker of the lithography extreme ultraviolet lithography machines you know attacking or monopolizing or co opting any one point in that chain you kind of capture capture the space and so what i'm trying to do is sort of explode the variance of possible ways to do ai in hardware by fundamentally reimagining how you embed ai algorithms into the physical world and in general by the way i i dislike the term agi artificial general intelligence i think it's very anthropocentric that we call human like or human level ai artificial general intelligence right i've spent my career so far exploring notions of intelligence that no biological brain could achieve right quantum form of intelligence right grokking systems that have multipartite quantum entanglement that you can provably not represent efficiently on a classical computer a classical deep learning representation and hence any sort of biological brain and so already you know i've spent my career sort of exploring the the wider space of intelligences and i think that space of intelligence inspired by physics rather than the human brain is very large and i think we're going through a moment right now similar to when we went from geocentrism to heal heliocentrism right but for intelligence we realized that human intelligence is just a point in a very large space of potential intelligences and it's both humbling for humanity it's a bit scary right that we're not at the center of the space but we made that realization for astronomy and we've survived and we've achieved technologies by indexing to reality we've achieved technologies that ensure our well-being for example we have satellites monitoring solar flares right that give us a warning and so similarly i think by letting go of this anthropomorphic anthropocentric anchor for ai we'll be able to explore the wider space of intelligences that can really be a massive benefit to our well-being and the advancement of civilization and still we're able to see the beauty and meaning in the human experience even though we're no longer in our best understanding of the world at the center of it i think there's a lot of beauty in the universe right i think life itself civilization this homo techno capital mimetic machine that we all live in right so you have humans technology capital memes everything is mhmm coupled to one another everything induces selective pressure on one another and it's a beautiful machine that has created us has created you know the technology we're using to speak today to the audience capture our speech here the technology we use to augment ourselves every day we have our phones i think the system is beautiful and the principle that induces this sort of adaptability and convergence on optimal technologies ideas and so on it's it's a beautiful principle that we're part of and i think part of iac is to appreciate this principle in a way that's not just centered on on humanity but kind of broader appreciate life you know the preciousness of of consciousness in our universe and because we cherish this beautiful state of matter we're in we we we gotta feel a responsibility to to scale it in order to preserve it because the options are to grow or die so if it turns out that the beauty that is consciousness in the universe is bigger than just humans the ai can carry that same flame forward does it scare you or are you concerned that ai will replace humans so during my career i had a moment where i realized that you know maybe we need to offload to machines to truly understand the universe around us right instead of just having humans with pen and paper solve it all and to me that sort of process of letting go of a bit of agency gave us way more leverage to understand the world around us a quantum computer is much better than a human to understand matter at the at the nanoscale similarly i think that humanity has a choice do we accept the opportunity to have intellectual and operational leverage that ai will unlock and thus ensure that we're taking along this path of growth and scope and scale of civilization we may dilute ourselves right there might be a lot of workers that are ai but overall out of our own self interest by combining and augmenting ourselves with ai we're gonna achieve much higher growth and much more prosperity right to me i think that the most likely future is one where humans augment themselves with ai i think we're already on this path to augmentation we have phones we use for communication we have on ourselves at all times we have wearables soon that have shared perception with us right like the human ai pen or i mean technically your tesla car has shared perception and so if you have shared experience shared context you communicate with one another and you have some sort of io really it's an extension of yourself and to me i think that humanity augmenting itself with ai and having ai that is not anchored to anything biological both will coexist and the way to align the parties we already have a sort of mechanism to align superintelligences that are made of humans and technology right companies are sort of large mixture of expert models where we have neural routing of tasks within a company and we have ways of economic exchange to align these behemoths and to me i think capitalism is the way and i do think that whatever configuration of matter or information leads to maximal growth will be where we converge just from like physical principles and so we can either align ourselves to that reality and and join the acceleration up in scope and scale of civilization or we can get left behind and try to decelerate and move back in the in the forest let go of technology and return to our primitive state and those are the two paths forward at least to me but there's a philosophical question whether there's a limit to the human capacity to align so let me bring it up as a form of argument this guy named dan hendricks and he wrote that he agrees with you that ai development could be viewed as an evolutionary process but to him to dan this is not a good thing as he argues that natural selection favors ais over humans and this could lead to human extinction what do you think if it is an evolutionary process and ai systems may have no need for humans i do think that we're actually inducing an evolutionary process on the space of ais through the market right right now we run ais that have positive utility to humans and that induces a selective pressure if you consider a neural net being alive when there's an api running instances of it on gpus yeah right and which apis get run the ones that have high utility to us right so similar to how we domesticated wolves and turned them into dogs that are very clear in their expression they're very aligned right i think there's gonna be an opportunity to steer ai and achieve highly aligned ai and i think that humans plus ai is a very powerful combination and it's not clear to me that pure ai would select out that combination so the humans are creating the selection pressure right now to create ais that are aligned to humans but you know given how ai develops and how quickly it can grow and scale one of the concerns to me one of the concerns is unintended consequences like humans are not able to anticipate all the consequences of this process the scale of damage that could be done through unintended consequences of ai systems is very large the scale of the upside yes right yeah by augmenting ourselves with ai is unimaginable right now the the opportunity cost we're we're at a fork in the road right whether we take the path of creating these technologies augment ourselves and get to climb up the kardashev scale become multiplanetary with the aid of ai or we have a hard cutoff of like we don't birth these technologies at all and then we leave all the potential upside on the table yep right and to me out of responsibility to the future humans we could carry right with higher carrying capacity by scaling civilization out of responsibility to those humans i think we have to make the greater grander future happen is there a middle ground between cutoff and all systems go is there some argument for caution i think like i said the market will exhibit caution every organism company consumer is acting out of self interest and they won't assign capital to things that have negative utility to them the problem is with the market is like you know there's not always perfect information there's manipulation there's bad faith actors that mess with the system it's not it's not always a rational and honest system well that's why we need freedom of information freedom of speech and freedom of thought in order to converge be able to converge on the subspace of technologies that have positive utility for us all right well let me ask you about pdoom probability of doom that's just fun to say but not fun to experience what is to you the probability that ai eventually kills all or most humans also known as probability of doom i'm not a fan of that calculation i think it's people just throw numbers out there and it's a very sloppy calculation right to calculate a probability you know let's say you model the world as some sort of markov process if you have enough variables or hidden markov process you need to do a stochastic path integral through the space of all possible futures not just the futures that your brain naturally steers towards right i think that the estimators of pduum are biased because of our biology right we're we've evolved to have bias sampling towards negative futures that are scary because that was an evolutionary optimum right and so people that are of let's say higher neuro neuroticism will just think of negative futures where everything goes wrong all day every day and and claim that they're doing unbiased sampling and and in a sense like they're not normalizing for the space of all possibilities and the space of all possibilities is like super exponentially large and it's very hard to have this estimate and in general i don't think that we can predict the future with that much granularity because of of chaos right if you have a complex system you have some uncertainty and a couple of variables if if you let time evolve you have this concept of a lyapunov exponent right a bit of fuzz becomes a lot of fuzz in our estimate exponentially so over time and i think we we need to show some humility that we can't actually predict the future all we know the only prior we have is the laws of physics and that's that's what we're arguing for the laws of physics say the system will want to grow and subsystems that are optimized for growth are more and replication are more likely in the future and so we should aim to maximize our current mutual information with the future and the path towards that is for us to accelerate rather than decelerate so i don't have a pdoom because i think that you know similar to the quantum supremacy experiment at google i was in the room when they were running the simulations for that that was an example of a quantum chaotic system where you you cannot even estimate probabilities of certain outcomes with even the biggest supercomputer in the world right and so that's an example of chaos and i think the system is far too chaotic for anybody to have an accurate estimate of the likelihood of certain futures if they were that good i think they would be very rich trading on the stock market but nevertheless it's true that humans are biased grounded in our evolutionary biology scared of everything that can kill us but we can still imagine different trajectories that can kill us we don't know all the other ones that don't necessarily but it's still i think useful combined with some basic intuition grounded in human history to reason about like what like looking at geopolitics looking at basics of human nature mhmm how can powerful technology hurt a lot of people and it just seems in grounded in that looking at nuclear weapons you can start to estimate pdoom in this in a maybe in a more philosophical sense not not a mathematical one philosophical meaning like is there a chance does human nature tend towards that or not i i think to me one of the biggest existential risks would be the concentration of the power of ai in the hands of the very few especially if it's a mix between the companies that control the flow of information and the government because that could set things up for a sort of dystopian future where only a very few an oligopoly in the government have ai and they could even convince the public that ai never existed and that opens up sort of these scenarios for authoritarian centralized control which to me is the the darkest timeline and the reality is that we have we have a prior we have a data driven prior of these things happening right when you give too much power when you centralize power too much humans do horrible things right and to me that has a much higher likelihood in my bayesian inference than sci fi based priors right like my prior came from the terminator movie and so when i talk to these ai doomers i just ask them to trace a path through this markov chain of events that would lead to our doom right and to actually give me a good probability for each transition and very often there's a unphysical or highly unlikely transition in that chain right but of course we're wired to fear things and we're wired to respond to danger and we're wired to deem the unknown to be dangerous because that's a good heuristic for survival right but there's much more to lose out of fear we have so much to lose so much upside to lose by preemptively stopping the positive futures from from happening out of fear and so i think that we shouldn't give in to fear fear is the mind killer i think it's also the civilization killer we can still think about the various ways things go wrong for example the founding fathers of this the united states thought about human nature and that's why the there's a discussion about the freedoms that are necessary they really deeply deliberated about that and i think the same could possibly be done for agi it is true that history human history shows that we tend towards centralization or at least when we achieve centralization a lot of bad stuff happens when there's a dictator a lot of dark bad things happen the question is can agi become that dictator can agi when developed become the centralizer because of its power maybe it has the same because of the alignment of humans perhaps the same tendencies the same stalin like tendencies to centralize and manage centrally mhmm the allocation of resources and you can even see that as an compelling argument on the surface level well agi is so much smarter so much more efficient so much better at allocating resources why don't we outsource it to the agi and then eventually whatever forces that corrupt the human mind with power could do the same for agi it would just say well humans are dispensable we'll get rid of them do the jonathan swift modest proposal from a few centuries ago i think the seventeen hundreds when he satirically suggested that i think it's in ireland that the the children of poor people are fed as food to the rich people and that would be a good idea because it decreases the amount of poor people and gives extra income to the poor people so it's on several accounts decreases the amount of poor people therefore more people become rich of course it misses a fundamental piece here that's hard to put into a mathematical equation of the basic value of human life so all of that to say are you concerned about agi being the very centralizer of power that you just talked about i do think that right now there's a bias towards over centralization of ai because of compute density and centralization centralization of data and how we're training models i think over time we're gonna run out of data to scrape over the internet and i think that well actually i'm working on increasing the compute density so that compute can be everywhere and acquire information and test hypotheses in the environment in a distributed fashion i think that fundamentally centralized cybernetic control so having one intelligence that is massive that you know fuses many sensors and is trying to perceive the world accurately predict it accurately predict many many variables and control it right enact its will upon the world i think that's just never been the optimum right like let's say you have a company you know if you have a company i don't know of ten thousand people that all report to the ceo even if that ceo is an ai i think it would struggle to fuse all of the information that is coming to it and then predict the whole system and then to enact its will what has emerged in nature and in corporations and all sorts of systems is a notion of sort of hierarchical cybernetic control right you have you know in a company it would be you have like the individual contributors they're self interested and and and they're trying to achieve their their tasks and they they have a a fine in terms of time and space if you will control loop and and then field of perception right they have their code base let's say you're in a software company they have their code base they iterate it on it intraday right and then the management maybe checks in it has a wider scope it has let's say five reports right and then it samples each person's update once per week and then you can go up the chain and you have larger time scale and and greater scope and that seems to have emerged as sort of the the optimal way to control systems and really that's what capitalism gives us right you have these hierarchies and you can even have like parent companies and so on and so that is far more fault tolerant in quantum computing that's where i feel it came from we have a a concept of of this fault tolerance and quantum error correction right quantum error correction is detecting a fault that came from noise predicting how it's propagated through the system and then correcting it right so it's a cybernetic loop and it turns out that decoders that are hierarchical and at each level of the hierarchy are local perform the best by far and are far more fault tolerant and the reason is if you have a non local decoder then you have one fault at at this control node and the whole system sort of crashes similarly to if you have you know one ceo that everybody reports to and that ceo goes on vacation the whole company comes to their crawl right and so to me i think that yes we're seeing a tendency towards centralization of ai but i think there's gonna be a correction over time where intelligence is gonna go closer to the perception and we're gonna we're gonna break up ai into smaller subsystems that communicate with one another and form a sort of meta system so if you look at the hierarchies there in the world today there's nations and those are hierarchical but in relation to each other nations are anarchic so it's an anarchy mhmm do you do you foresee a world like this where there's not a over what'd you call it a centralized cybernetic control centralized locus of control yeah is so like that's suboptimally you're saying yeah so it would be always a state of competition at the very yeah top level yeah just like you know in a company you may have like two units working on similar technology and competing with one another and you you prune the one that performs not as well right and that's a sort of selection process for a tree or a product gets killed right and then a whole or it gets fired and that's this process of of trying new things and and and shedding old things that didn't work is this it's what gives us adaptability and helps us converge on you know the technologies and things to do that are most good i just hope there's not a failure mode that's unique to agi versus humans because you're describing human systems mostly right now right i just hope when there's a monopoly in agi in one company that we'll see the same thing we see with humans which is another company we'll spring up and start competing i mean that's been the case so far right we have openai we have anthropic now we have xai you know we had meta even for open source and now we have mistral right which is highly competitive and so that's the beauty of capitalism you don't have to trust any one party too much because we're kind of always hedging our bets at every level there's always competition and that's the most beautiful thing to me at least is that the whole system is always shifting and always adapting and maintaining that dynamism is how we avoid tyranny right making sure that everyone has access to to these tools to to these models and can contribute to the research avoids a sort of neural tyranny where very few peep peep people have control over ai for the world and and use it to oppress those around them when you were talking about intelligence you mentioned multipartite quantum entanglement mhmm so high level question first is what do you think is intelligence when you think about quantum mechanical systems and you observe some kind of computation happening in them what do you think is intelligent about the kind of computation the universe is able to do a small small inkling of which is the kind of computation the human brain is able to do i i would say like intelligence and computation aren't quite the same thing i think that the universe is very much you know doing a quantum computation if you had access to all the degrees of freedom you can and a very very very large quantum computer with many many many qubits let's say a few qubits per planck volume right which was more or less the pixels we have then you you'd be able to simulate the whole universe right on a on a sufficiently large quantum computer assuming you're looking at a finite volume of course of the universe i think that at least to me intelligence is the you i go back to cybernetics right the ability to perceive predict and control our world but really it's nowadays it seems like a lot of intelligence we use is more about compression right mhmm it's about it's about operationalizing information theory right in information theory you have the notion of entropy of a distribution or a system and entropy tells you that you need this many bits to encode this distribution or this subsystem if you had the most optimal code mhmm and ai at least the way we we do it today for lms and for quantum is is very much trying to minimize relative entropy between our models of the world and the world distributions from the world and so we're learning we're searching over the space of computations to process the world to find that compressed representation that has distilled all the variance in noise and entropy right and originally i i came to quantum machine learning from the study of black holes because the entropy of black holes is very interesting in a sense they're physically the most dense objects in the universe you can't pack more information spatially any more densely than in black hole and so i was wondering how do black holes actually encode information what is their compression code and so that got me into the space of algorithms to search over space of quantum codes and it got me actually into also how do you acquire quantum information from the world right so something i've worked on this is public now is quantum analog digital conversion so how do you capture information from the real world in superposition and not destroy the superposition but digitize for a quantum mechanical computer information from the real world and so if you have an ability to capture quantum information and search over learned representations of it now you can learn compressed representations that may have some useful information in their latent representation right and i think that many of the problems facing our civilization are actually beyond this this complexity barrier right i mean the greenhouse effect is a quantum mechanical effect right chemistry is quantum mechanical you know nuclear physics is quantum mechanical a lot of biology and and and and protein folding and so on is affected by quantum mechanics and so unlocking an ability to augment human intellect with quantum mechanical computers and quantum mechanical ai seemed to me like a fundamental capability for civilization that we we needed to develop so i spent several years doing that but over time i kinda grew weary of the the timelines that were starting to look like nuclear fusion one high level question i can ask is maybe by way of definition by way of explanation what is a quantum computer and what is quantum machine learning so a quantum computer really is a quantum mechanical system over which we have sufficient control and it can maintain its quantum mechanical state mhmm and quantum mechanics is how nature behaves at the very small scales when things are very small or very cold and it's actually more fundamental than probability theory so we're used to things being this or that but we're not used to thinking in superpositions because well our brains can't can't do that so we we have to translate the quantum mechanical world to say linear algebra to grok it unfortunately that translation is exponentially inefficient on average you have to represent things with very large matrices but really you can make a quantum computer out of many things right and we've seen all sorts of players you know from neutral atoms trapped ions superconducting metal photons in at different frequencies i think you can make a quantum computer out of many things but to to me the thing that was really interesting was both quantum machine learning was about understanding the quantum mechanical world with quantum computers so embedding the physical world into ai representations and quantum computer engineering was embedding ai algorithms into the physical world so this bidirectionality of embedding physical world into ai ai into the physical world the symbiosis between physics and ai really that's the sort of core of my quest really even to this day after quantum computing it's still in this sort of journey to merge really physics and ai fundamentally so quantum machine learning is a way to do machine learning on a representation of nature that is you know stays true to the quantum mechanical aspect of nature yeah it's learning quantum mechanical representations that would be quantum deep learning alternatively you can try to do classical machine learning on a quantum computer i wouldn't advise it because you may have some speedups but very often the speedups come with huge costs using a quantum computer is very expensive why is that because you assume the computer is operating at zero temperature which no physical system in the universe can achieve that temperature so what you have to do is what i've been mentioning this quantum error correction process which is really an algorithmic fridge right it's trying to pump entropy out of the system trying to get it closer to to zero temperature and when you do the calculations of how many resources it would take to say do deep learning on a quantum computer classical deep learning it's there's just such a huge overhead it's not worth it it's like thinking about shipping something across a city using a rocket and going to orbit and back it doesn't make sense just use an you know delivery truck right what kind of stuff can you figure out can you predict can you understand with quantum deep learning that you can't with deep learning so incorporating quantum mechanical systems into the into the learning process i think that's a great question i mean fundamentally it's any system that has sufficient quantum mechanical correlations that are very hard to capture for classical representations then there should be an advantage for a quantum mechanical representation over a purely classical one the question is which systems have sufficient correlations that are very quantum but is also which systems are still relevant to industry that's a big question you know people are leaning towards chemistry nuclear physics i've worked on actually processing inputs from quantum sensors right if you have a network of quantum sensors they've captured a quantum mechanical image of the world and how to post process that that becomes a sort of quantum form of machine perception and so for example fermilab has a project exploring detecting dark matter with these quantum sensors mhmm and to me that's in alignment with my quest to understand the universe ever since i was a child and so someday i hope that we can have very large networks of quantum sensors that help us peer into the earliest parts of the the universe right for example the ligo is a quantum sensor right it's just a very large one so yeah i would say quantum machine perception simulations right crocking quantum simulations similar to alphafold right alphafold understood the probability distribution over configurations of proteins you can understand quantum distributions over configurations of electrons more efficiently with quantum machine learning you coauthored a paper titled a a universal training algorithm for quantum deep learning that involves back prop with a queue very well done sir very well done how does it work is it is there some interesting aspects you can just mention on how kinda you know back prop and some of these things you know for classical machine learning transfer over to the mhmm the quantum machine learning yeah that was that was a that was a funky paper that was one of my first papers in in quantum deep learning everybody was saying oh i think deep learning is gonna be sped up by quantum computers and i was like well the best way to predict the future is to invent it so here's a hundred page paper have fun essentially you you know quantum computing is usually you embed reversible operations into a quantum computation and so the trick there was to do a feed forward operation and do what we call a phase kick but really it's just a force kick you just kick the system with a certain force that is you know proportional to your loss function that you you wish to optimize and then by performing uncomputation you start with the superpositions over a superposition over parameters right which is pretty funky now you're not just you don't have just a point for parameters you have a superposition over many potential parameters right mhmm and our goal is to use phase kicks somehow right to adjust parameters because phase kicks emulate having the parameter space be like a a particle in n dimensions mhmm and you're trying to get the schrodinger equation schrodinger dynamics in the loss landscape of the neural network mhmm right and so you do an algorithm to induce this face kick which you know involves a feed forward a kick and then when you uncompute the feed forward then all the errors in these phase kicks and these forces back propagate and hit each one of the parameters throughout the layers and if you alternate this with an emulation of kinetic energy then it's kind of like a particle moving in n dimensions a quantum particle and the advantage in principle would be that it can tunnel through the landscape and find new optima that would have been difficult for stochastic optimizers but again this is kind of a theoretical thing and in practice with at least the current architectures for quantum computers that we have planned you know such algorithms would be extremely expensive to run so maybe this is a good place to ask the difference between the different fields that you've had a toe in mhmm so mathematics physics engineering and also you know entrepreneurship like the different layers of the stack i think a lot of the stuff you're talking about here is a little bit on the math side maybe physics almost working in theory what's the difference between math physics engineering and you know make making a product for quantum computing for quantum machine learning yeah i mean you know some of the original team for the tensorflow quantum project which we started you know in school at university of waterloo there was myself you know initially i was a physicist a plyometrician mathematician we had a computer scientist we had mechanical engineer and then we had a physicist that was experimental primarily and so putting together teams that are very cross disciplinary and and figuring out how to communicate and and share knowledge is really the key to doing this sort of interdisciplinary engineering work i mean there is there is a big difference you know in mathematics you can explore mathematics for mathematics' sake in physics you're applying mathematics to understand the world around us and in engineering you're trying to you're trying to hack the world right you're trying to find how to apply the physics that i know my knowledge of the world to to to do things well in quantum computing in particular i think there's a just a lot of limits to engineering it just seems to be extremely hard yeah so there's a lot of value to be exploring quantum computing quantum machine learning in theory right in with with with math so i guess one question is why is it so hard to build a quantum computer what are what's your view of timelines in bringing these ideas to life right i i think that you know an overall theme of my company is that we have folks that are you know there's a sort of exodus from quantum computing and we're we're going to broader physics based ai that is not quantum so that gives you a hint and so we should say the name of your company is xtrappic xtrappic that's right and we do physics based ai primarily based on thermodynamics rather than quantum mechanics but essentially a quantum computer is very difficult to build because you have to induce this sort of zero temperature subspace of information and the way to do that is by encoding information you encode a code within a code within a code within a code and so there's a lot of redundancy needed to do this error correction but ultimately it's a sort of algorithmic refrigerator really it's just pumping out entropy out of the sys the subsystem that is virtual and and delocalized that represents your quote unquote logical qubits a k a the the payload quantum bits in which you actually want to do run your quantum mechanical program it's very difficult because in order to scale up your quantum computer you need each component to be of sufficient quality for it to be worth it because if you try to do this error correction this quantum error correction process in each quantum bit and your control over them isn't if it's insufficient it's not worth scaling up you're actually adding more errors than you remove and so there's this notion of a threshold where if your quantum bits are of sufficient quality in terms of your control over them it's actually worth scaling up and actually in recent years people have been crossing the threshold and it's starting to be worth it and so it's just a very long slog of engineering but ultimately it's really crazy to me how much exquisite level of control we have over these systems it's actually quite crazy and we're people are crossing you know they're achieving milestones it's just you know in general the media always gets ahead right of where the technology is there's a bit too much hype it's good for fundraising but sometimes you know it causes winters right it's the hype cycle i'm bullish on quantum computing on a ten fifteen year timescale personally but i think there's other quests that can be done in the meantime i think it's in good hands right now well let me just explore different beautiful ideas large or small in quantum computing that might jump out at you from memory someone you coauthored a paper titled asymptotically limitless quantum energy teleportation via qdit probes so just out of curiosity can you explain what a qdit is this is a qbit yeah it's a it's a destate qdit it's multidimensional multidimensional right so it's like well you know can you have a notion of like an integer floating point that is quantum mechanical that's something i've had to think about i think that research was a precursor to later work on quantum analog digital conversion there there was interesting because during my master's i was trying to understand the energy and entanglement of the vacuum right of emptiness emptiness has energy which is very weird to say and our equations of cosmology don't match our calculations for the amount of quantum energy there are there is in the fluctuations and so i was trying to hack the energy of the vacuum right and the reality is that you can't just directly hack it it doesn't it's not technically free energy your lack of knowledge of the fluctuations means you can't extract the energy but just like you know the stock market if you have a stock that's correlated over time the vacuum is actually correlated so if you measured the vacuum at one point you acquired information if you communicated that information to another point you can infer what configuration the vacuum is in to some precision and statistically extract on average some energy there so you've quote unquote teleported energy to me that was interesting because you could create pockets of negative energy density which is energy density that is below the vacuum which is very weird because we don't understand how the vacuum gravitates and there are theories where the vacuum or the canvas of space time itself is really a a canvas made out of quantum entanglement and i was studying how decreasing energy of the vacuum locally increases quantum entanglement which is very funky and so the thing there is that you know if you're into you know weird theories about you know uaps and whatnot you know you could try to imagine that they're they're around and and how would they propel themselves right how would they go faster than the speed of light you would need a sort of negative energy density and to me i gave it the old college try trying to hack the energy of the vacuum and hit the limits allowable by the laws of physics but there's all sorts of caveats there where you can't extract more than you've you've put in obviously but you're saying it's possible to teleport the energy because you can extract information in one place and then make based on that some kind of prediction mhmm about another place yep i'm not sure what to make of that yeah i mean it's it's allowable by the laws of physics the the reality though is that the correlations decay with distance and so sure you're gonna have to pay the price not too far away from where you extract it sure right the precision decreases i mean in terms of your ability but but still but since you mentioned uaps we talked about intelligence and i forgot to ask would what's your view on the other possible intelligences that are out there at the the meso scale do you think there's other intelligent alien civilizations is that useful to think about how often do you think about it i think it's i think it's useful to think about it's useful to think about because we gotta ensure we're antifragile and we're you know trying to increase our capabilities as fast as possible because we could get disrupted like there's no laws of physics against there being life elsewhere that could evolve and become an advanced civilization and and eventually come to us mhmm do i think they're here now i'm not sure i mean i've i've i've read what most people have read on the the topic i think it's interesting to consider and to me it's a useful thought experiment to instill a sense of urgency in developing technologies and increasing our capabilities to make sure we don't get disrupted right whether it's a form of of ai that disrupts us or a foreign intelligence from a different planet like either way like increasing our capabilities and becoming formidable as humans i think that's that's really important so that we're robust against whatever the universe throws at us but to me it's also an interest an interesting challenge and thought experiment on how to perceive intelligence this has to do with quantum mechanical systems this has to do with with any kind of system that's not like humans so to me the thought experiment is say the aliens are here or they are directly observable or just too blind too self centered don't have the right sensors or don't have the right processing of the sensor data to see the obvious intelligence that's all around us well that's why we work on quantum sensors right they can sense gravity yeah but there could be so that's a good one but there could be other stuff that's not even the in the currently known forces of physics right there could be some other stuff and the most entertaining thought experiment to me is that it's other stuff that's obvious it's not like we don't we lack the sensors it's all around us you know you know the the consciousness being one possible one but there could be stuff that's just like obviously there and once you know it it's like oh right right that's that's that the thing we thought is somehow emergent from the laws of physics we understand them it's actually a fundamental part of the universe and can be incorporated in physics most understood statistically speaking right if we observe some sort of alien life it would most likely be some sort of virally self replicating von neumann like probe system right and and it's possible that there you know there are such systems that i don't know what they're doing at the bottom of the ocean allegedly but maybe they're you know collecting minerals from the bottom of the ocean yeah but that wouldn't violate violate any of my priors but am i certain that these systems are here and it it'd be difficult for me to say so right i only have secondhand information about there being data about the bottom of the ocean yeah but you know could it be things like memes could it be thoughts and ideas could they be operating in that medium could aliens be the very thoughts that come into my head like what do you have you how do you know that how do you know that that what's the origin of ideas in your mind when an idea comes to your head show me where it originates i mean frankly when i had the idea for the type of computer i'm building now i think it was eight years ago now it really felt like it was being beamed from space it it just i was in bed just shaking just thinking it through and i don't know but do i believe that legitimately i don't think so but you know i i think that alien life could take many forms and i think the notion of intelligence and the notion of life needs to be expanded much more broadly to be less anthropocentric or biocentric just to linger a little longer on on quantum mechanics what's through all your explorations of quantum computing what's the coolest most beautiful idea that you've come across that has been solved or has not yet been solved i think the journey to understand something called adscft so the journey to understand quantum gravity through this picture where a hologram of lesser dimension is actually dual or exactly corresponding to a bulk theory of quantum gravity of an extra dimension and the fact that this sort of duality comes from trying to learn deep learning like representations of the boundary mhmm and so at least part of my journey someday on my bucket list is to apply quantum machine learning to these sorts of systems these cfts or they're called syk models and learn an emergent geometry from from the boundary theory and so we can have a form of machine learning helps us to help us understand quantum gravity right which is you know still a holy grail that i would like to hit before i leave this earth what what do you think is going on with black holes as information storing and processing units what do you think is going on with black holes black holes are really fascinating objects they're at the inter interface between quantum mechanics and gravity and so they help us test all sorts of ideas i think that you know for many decades now there's been sort of this black hole information paradox that things that fall into the black hole seem to we've seem to have lost their information now i think there's this firewall paradox that has been allegedly resolved in recent years by you know a former peer of mine who's now a professor at berkeley and there it seems like there is as information falls into a black hole it's sort of there's sort of a sedimentation right as you as you get closer and closer to the horizon from the point of view of the observer on the outside the object slows down infinitely as it gets closer and closer and so everything that is falling to a black hole from our perspective gets sort of sedimented and tacked on to the near horizon and at some point it gets so close to the horizon it's in the proximity or the scale which in which quantum effects and quantum fluctuations matter and there some that and falling matter could interfere with sort of the traditional pictures that it can interfere with the creation and annihilation of particles and antiparticles in the vacuum and through this interference one of the particles gets entangled with the in falling information and one of them is now free and escapes and that's how there's sort of mutual information between the outgoing radiation and the in falling matter but getting that calculation right i think we're only just starting to put the pieces together but there's a few pothead like questions i wanna ask you sure so one does it terrify you that there's a giant black hole at the center of our galaxy i don't know i i i just want to you know set up shop near it to to fast forward you know meet meet a future civilization right like if we have a limited lifetime if you could go orbit a black hole and emerge so if you were like if there's a special mission that could take you to a black hole would you volunteer to go travel to orbit and not obviously not fall into it that's that's obvious so it's obvious to you that everything's destroyed inside a black hole like all the information that makes up guillaume is destroyed maybe on the other side beth geisel's emergence and it's just all like is tied together in some deeply meme of old way yeah i mean that's a great question we we have to answer what black holes are are they are we punching a hole through space time and creating a pocket universe it's possible right then then that would mean that if we ascend the kardashev scale to you know beyond kardashev type three we could engineer black holes with specific hyperparameters to transmit information to new universes we create and so we can have progeny right that are new universes and so we even though our universe may reach a heat death we may have a way to have a legacy right and so we don't know yet we need to ascend the kardashev scale to answer these questions right to peer into that regime of higher energy physics and maybe you can speak to the kardashev scale for people who don't know so one one of the sort of meme like principles and goals of the iac movement is to ascend the kardashev scale what is the kardashev scale and when do we wanna ascend it the kardashev scale is a measure of our energy production and consumption and really it's a logarithmic scale and kardashev type one is a milestone where we are producing the equivalent wattage to all the energy that is incident on earth from the sun kardashev type two would be harnessing all the energy that is output by the sun and i think type three is like the whole galaxy equivalent i think flowable yeah yeah yeah and then some people have some crazy type four and five but i i don't know if i believe in those but to me it seems like from the first principles of thermodynamics that again this there's this concept of thermodynamic driven dissipative adaptation where you know life evolved on earth because we have this sort of energetic drive from the sun right we have incident energy and life evolved on earth to capture figure out ways to best capture that free energy to maintain itself and and grow and i think that that principle it's not special to our earth sun system we can extend life well beyond and we kind of have a responsibility to do so because that's the process that brought us here so we don't even know what it has in store for us in the future it could be something of beauty we can't even imagine today right mhmm so this is probably a good place to talk a bit about the eac movement in a substack blog post titled what the fuck is eac or actually what the f star is eac you write strategically speaking we need to work towards several overarching civilization goals that are all interdependent and the four goals are increase the amount of energy we can harness as a species climb the kardashev gradient in the short term this almost certainly means nuclear fission increase human flourishing via pro population growth policies and pro economic growth policies create artificial general intelligence the single greatest force multiplier in human history and finally develop interplanetary and interstellar transport so that humanity can spread beyond the earth could you build on top of that to maybe say what to you is the eap movement what are the goals what are the principles the goal is for the human techno capital mimetic machine to become self aware and to hyperstitiously engineer its own growth so let's let's deconfess that each of those words so you have humans you have technology yeah you have capital and then you have you have memes information right and all of those systems are coupled with one another right humans work at companies they acquire and allocate capital and humans communicate via memes and information propagation and our goal was to have a sort of viral optimistic movement that is aware of how the system works fundamentally it seeks to grow and we simply want to lean into the natural tendencies of the system to adapt for its own growth so in that way you're right the eac is literally a memetic optimism virus that is constantly drifting mutating and propagating in a decentralized fashion so memetic optimism virus so you do want it to be a virus to to maximize the spread and it's superstitious therefore the optimism will incentivize its growth we see eac as a sort of metaheuristic a a sort of very thin cultural framework from which you can have much more opinionated forks right fundamentally we just say that it's good the what got us here is this adaptation of the whole system mhmm you know based on thermodynamics and that process is good and we should keep it going right that is the core thesis everything else is okay how how do we ensure that we maintain this malleability and adaptability while clearly not suppressing variance and and maintaining free speech freedom of thought freedom of information propagation and freedom to do ai research is important for us to converge the fastest on the space of technologies ideas and whatnot that lead to this growth and so ultimately there's been quite a few forks some are just memes but some are more serious right vitalik peterson recently made a diac fork he has his own sort of fine tunings of eac does anything jump out to memory of the unique characteristic of that fork from vitalik i would say that it's it's trying to find a middle ground between eac and sort of ea and ai safety to me like having a movement that is opposite to what was the mainstream narrative that was taking over silicon valley was important to sort of shift the dynamic range of opinions true and you know it's it's like the balance between centralization and decentralization the real optimum is always somewhere in the middle right but but for eac we're pushing for entropy novelty disruption malleability speed rather than being like sort of conservative suppressing thought suppressing speech adding constraints adding too many regulations slowing things down and so it's kind of we're trying to bring balance to the force right the systems balance to the force it's human civilization yeah it's literally the forces of constraints versus the entropic force that makes us explore right systems are optimal when they're at the edge of criticality between order and chaos right between constraints energy minimization and entropy right systems want to equilibrate balance these two things and so i thought that the balance was lacking and so we created this movement to to bring balance well i like how i like the sort of visual of the landscape of ideas evolving through forks so kinda thinking on the other part of history thinking of marxism as the original depository and then soviet communism is a fork of that and then then maoism is a fork of the the of marxism and communism and so those those are all forks they're exploring different ideas thinking of culture almost like code right nowadays i mean you're what you prompt in the lm or what you put in the constitution of an lm is is is basically its cultural framework what it believes right and you can share it on github nowadays so starting trying to take inspiration from what has worked in this sort of machine of software to adapt over the space of code could we apply that to culture and our goal is to not say you should live your life this way x y z is to set up a process where people are always searching over subcultures and competing for mindshare and i think creating this malleability of culture is super important for us to converge onto the cultures and the heuristics about how to live one's life that are updated to to modern times because there's really been a a sort of vacuum of of spirituality and culture people don't feel like they belong to any one group and there's been parasitic ideologies that have taken up opportunity to to populate this petri dish of of minds right elon calls it the mind virus we call it the the the decel mind virus complex which is the decelerative that is kind of the the overall pattern between all of them there's many variants as well and so you know if there's a sort of viral pessimism decelerative movement we needed to have not only one movement but you know many many variants so it's very hard to pinpoint and stop but the overarching thing is nevertheless a kind of mimetic optimism pandemic so i mean okay let me ask you do you think eac to some degree is a cult define cult i think a lot of human progress is made when you have independent thought so you have individuals that are able to think freely and very powerful mimetic systems can kinda lead to group think there's something in human nature that leads to like mass hypnosis mass hysteria we we start to think alike yeah whenever there's a sexy idea that captures our minds and so it's actually hard to like break us apart like pull us apart diversify a thought so i'm to that degree to to which degree is everybody kinda chanting e act e act like the sheep in animal farm well first of all it's fun it's rebellious right like you know many i i i think we lean into there there there's this concept of sort of meta irony right of of sort of being on the boundary of like we're not sure if they're serious or not and it's it's much more playful and much more fun right like for example we talk about thermodynamics being our god mhmm right and sometimes we do cult like things but there's no like ceremony and and roads and whatnot not yet not yet but ultimately yeah i mean i totally agree that it seems to me that humans wanna feel like they're part of a group so they naturally try to agree with their neighbors and and find common ground and and that leads to sort of mode collapse in the space of ideas right we used to have sort of one cultural island that was allowed it was a typical subspace of thought and anything that was diverting from that subspace of thought was suppressed or you were canceled right now we've created a new mode but the whole point is that we're not trying to have a very restricted space of thought there's not just one way to think about eac and its many forks and and the point is that there are many forks and there can be many clusters and many islands and i shouldn't be in control of it in any way i mean there's no formal org whatsoever i just put out tweets and and certain blog posts and people are free to defect and fork if there's an aspect they don't like and so that makes it so that there should be a sort of deterritorialization in the space of ideas so that we don't end up in one cluster that's very cult like and so cults usually they they don't they don't allow people to defect or start competing forks whereas we encourage it right do you think just the humor the pros and cons of humor and meme so in some sense meme there's like a wisdom to memes what is it the magic theater what book is that from hermann hesse steppenwolf i think but there there's a there's a kind of embracing of the absurdity that seems to get to the truth of things but at the same time it can also decrease the quality and the rigor of the discourse yeah do you feel the tension of that yeah so initially i think what allowed us to grow under the radar was because it was camouflaged as sort of meta ironic right we would sneak in you know deep truths within a package of humor and humor and memes and what are called shitposts right and i think that was purposefully a sort of camouflage against those that seek status and do not want to it's very hard to argue with a cartoon frog or a a cartoon of an intergalactic jeff bezos and take yourself seriously yeah and so that allowed allowed us to grow pretty rapidly in the early days but of course like that that's you know essentially people get steered their notion of the truth comes from the data they see from from the information they're fed and the information people are fed is determined by algorithms right and really what we've been doing is sort of engineering what we call high mimetic fitness packets of information so that they can spread effectively and carry a message right so it's it's kind of a a vector to spread spread the message and and yes we've been using sort of techniques that are optimal for for today's algorithmically amplified information landscapes but i think we're reaching the point of you know scale where we can have serious debates and serious conversations and you know that's why we're considering doing a a bunch of debates and and having more serious long form discussions because i don't think that the timeline is optimal for sort of very serious thoughtful discussions you get you get rewarded for sort of polarization right and so even though we started a movement that is literally trying to polarize the the tech ecosystem at the end of the day so that we can have a conversation and find an optimum together i mean that's kind of what i try to do with this podcast given the landscape of things to still have long form conversations but there is a degree to which absurdity is fully embraced in fact this very conversation is multilevel absurd so first of all i should say that i just very recently had a conversation with jeff bezos and i would love to hear your beth bezos' opinions of jeff bezos speaking of intergalactic jeff bezos what do you think of that particular individual whom your name is inspired yeah i mean i think jeff is really great i mean he's built one of the most epic companies of all time he's leveraged the techno capital machine and techno capital acceleration to give us what we wanted right we want quick delivery very convenient at home low prices right he understood how the machine worked and how to harness it right like running the company not drink trying to take profits too early putting it back putting letting the system compound and keep improving and you know arguably i think amazon's invested some of the most amount of capital in robotics out there and certainly with the birth of aws kind of enabled the sort of tech boom we've seen today that has paid the salaries of you know i guess myself and all of our friends to some extent and so i i think we can all be grateful to you know jeff and he's one of the great entrepreneurs out there one of the best of all time unarguably and of course the the work at blue origin similar to the work at spacex is trying to make humans a multi planetary species which seems almost like a bigger thing than the capitalist machine or is the capitalist machine at a different time scale perhaps yeah i i think that you know companies they tend to optimize you know quarter over quarter maybe a few years out but individuals that want to leave a legacy can think on a multi decade or multi century time scale and so the fact that some individuals are such good capital allocators that they unlock the ability to allocate capitals to goals that take us much further or are much further looking you know elon's doing this with spacex putting all this capital towards getting us to mars jeff is trying to build blue origin and i think he wants to build o'neil cylinders and get industry off planet which i think is brilliant i think you know just overall i'm i'm four billionaires i know this is controversial statement sometimes but i think that in a sense it's kind of a a proof of stake voting right like if you've acquire if you've allocated capital efficiently you get you unlock more capital to allocate just because clearly you know how to allocate capital more efficiently which is in contrast to politicians that get elected because they speak the best on tv right not because they have a proven track record of allocating taxpayer capital most efficiently and so that's why for capitalism over say giving all our money to the government and letting them figure out how to allocate it so yeah why do you think it's a viral and a popular meme to criticize billionaires since you mentioned billionaires why do you think there's quite a widespread criticism of of people with wealth especially those in the public eye like jeff and elon and mark zuckerberg and who else bill gates yep i i think a lot of people would instead of trying to understand how the techno capital capital machine works and realizing they have much more agency than they think they'd rather have the sort of victim mindset i'm just subjected to this machine it is oppressing me and and the successful players clearly must be must must be evil because they've been successful at this game that i'm not successful at but you know i've i've managed to get some people that were in that mindset and make them realize how the the techno capital machine works and how you can harness it for your own good and and for the good of others and by creating value you capture some of the value you create for the world and and that sort of positive sum mindset shift is so potent and really that's what that's what we're trying to do by scaling eac is sort of unlocking that higher level of agency like actually you have you're far more in control of the future than you think you have agency to change the world go out and do it you have here's permission each individual yes has agency the motto keep building is often heard right what does that mean to you and what does it have to do with diet coke oh diet the way thank you so much for the red bull it's it's working pretty well i'm feeling pretty good awesome well so so building technologies and and building it doesn't have to be technologies just building in general means you know having agency trying to change the world by creating let's say a company which is a self sustaining organism that you know accomplishes a function in the broader techno capital machine to us that's the way to achieve change in the world that you'd like to see rather than say pressuring politicians or creating nonprofits that you know nonprofits once they run out of money their function can no longer be accomplished you're kind of deforming the market artificially compared to sort of subverting or coercing the market to or or dancing with the market to to convince it that actually this function is important adds value and here it is right and so i think you know this is sort of the way between the sort of degrowth like esg approach versus say elon right the degrowth approach is like we're gonna manage our way out of a climate crisis and elon is like i'm gonna build a company that is self sustaining profitable and growing and it's we're gonna innovate our way out of this dilemma right and and we're trying to get people to do the latter rather than the former at all scales elon is an interesting case so you are a proponent you celebrate elon but he's also somebody who has for a long time warned about the dangers the potential dangers existential risks of artificial intelligence how do you square the two is that a contradiction to you it is somewhat because he's very much against regulation in many aspects but for ai he's he's definitely you know a proponent of of regulations i think i think overall you know he he saw the dangers of say openai you know cornering the market and then getting to have the monopoly over the cultural priors that you can embed in these llms that then you know as as llms now become the source of truth for people then you can shape the culture of the people and so you can control people by controlling lms and he saw that just like it was the case for social media if you shape the function of information propagation you can shape people's opinions mhmm he's he he sought to make a competitor so at least like i think we're very aligned there that you know they're the way to a good future is to maintain sort of adversarial equilibria between the various ai players i'd love to talk to him to understand sort of his thinking about how to make you know how to advance ai going forward i mean he's also hedging his bets i would say you know with neuralink right i think if he can't stop the progress of ai you know he's building the technology to merge so you know look at the actions not just the words but well i mean there's some degree where being concerned maybe using human psychology being concerned about threats all around us is a motivator mhmm like it's an encouraging thing i operate much better when there's a deadline the fear of the deadline like can i for myself create artificial things like i i wanna create in myself this kind of anxiety as if something really horrible will happen if i miss the deadline i think there's some degree of of that here because creating ai that's aligned with humans has a lot of potential benefits and so a different way to reframe that is if you don't you're we're all gonna die it just seems to be a very powerful psychological formulation of the goal of creating human aligned ai i think that anxiety is good i think like i said i want the the free market to to create aligned ais that are reliable and i think that's what he's trying to do with xai so i'm all for it what what i am against is sort of stopping let's say the open source ecosystem from thriving right by let's say in the executive order claiming that open source lms or dual use technologies and should be government controlled then everybody needs to register their gpu and their big matrices with the government and i think that extra friction will dissuade a lot of hackers from contributing hackers that could later become the the researchers that make key discoveries that push us forward right including discoveries for ai safety and so i think i i just wanna maintain ubiquity of opportunity to contribute to ai and and to own a piece of the future right it can't just be legislated you know behind some wall where only a few players get to play the game i mean so the eac movement is often sort of caricatured to mean sort of progress and innovation at all at all costs doesn't matter how unsafe it is doesn't matter if it cause a lot of damage you just build build cool shit as fast as possible stay up all night with a diet coke whatever it takes i i think i guess i don't know if there's a question in there but how important to you and what you've seen the different formulations of eac is safety is ai safety i think again i think like if there was no one working on it i think i would be a proponent sure of it i think again our goal is to sort of bring balance and obviously a sense of urgency is a useful tool right to make progress it hacks our dopaminergic systems and gives us energy to to work late into the night i think also having a higher purpose you're contributing to right at the end of the day it's like what am i contributing to i'm contributing to the growth of this beautiful machine so that we can seek to the stars that's really inspiring that's also a sort of neuro hack so you're saying ai safety is important to you but right now the landscape of ideas you see is ai safety as a topic is used more often to gain centralized control so in that sense you're resisting it as a proxy for centralized gaining centralized control yeah i i i just think we we have to be careful because you know safety is just the perfect cover for sort of centralization of power and covering up eventually corruption i don't i'm not saying it's corrupted now but it could be down the line and really if you if you let the argument run like there's no amount of sort of centralization of control that will be enough to ensure your safety there's always more nine nine nines of p safety that you can gain you know nine nine nine point nine nine nine nine nine nine nine percent safe maybe you want another nine oh please give us full access to everything you do full surveillance and and and frankly those that are proponents of ai safety have proposed like having a global panopticon mhmm right where you have centralized perception of everything going on and to me that just opens up the door wide open for a sort of big brother nineteen eighty four like scenario and that's not a future i wanna live in because we know we have some examples throughout history when that did not lead to a good outcome right you mentioned you founded a company xtropic that recently announced a fourteen point one million seed round what's the goal of the company you're talking about a lot of interesting physics things so what what are you up to over there that you can talk about yeah i mean you know originally we weren't gonna announce last week but i think with the doxing and disclosure we got our our hand forced so we we had to disclose roughly what we're we're doing but really xtropic was born from my dissatisfaction and that of my colleagues with the the quantum computing road map right quantum computing was sort of the first path to physics based computing that you know was trying to commercially scale and i was working on physics based ai that runs on these physics based computers but ultimately our greatest enemy was this noise this pervasive problem of noise that you know as i mentioned you have to constantly pump out the noise out of the system to maintain this pristine environment where quantum mechanics can take effect and that constraint was just too much it's too costly to do that and so we were wondering right as generative ai is sort of eating the world more and more of the world's computational workloads are focused on generative ai how could we use physics to engineer the ultimate physical substrate for generative ai right from first principles of physics of information theory of computation and ultimately of thermodynamics right and so what we're seeking to build is a physics based computing system and physics based ai algorithms that are inspired by out of equilibrium thermodynamics or harness it directly to do machine learning as a physical process so what does that mean machine learning is a physical process is that hardware is it software is it both is it trying to do the full stack in some kind of unique way yes it it it is full stack and so we're folks that have built you know differentiable programming into the quantum computing ecosystem with tensorflow quantum one of my cofounders of tensorflow quantum is the cto trevor mccourt we have some of the best quantum computer architects those that have designed ibm's and aws's systems they've left quantum computing to help us build what we call actually a thermodynamic computer a thermodynamic computer well actually that's something around tensorflow quantum what lessons have you learned from tensorflow quantum maybe you can speak to like what what it takes to create essentially what like a software api to a quantum computer right i mean that was that was a challenge to build to invent to build and then to get to run on the real devices can you actually speak to what it is yeah so tensorflow quantum was an attempt at well i mean i guess we succeeded at combining deep learning or differentiable classical programming with quantum computing and turn quantum computing into or have types of programs that are differentiable in quantum computing and you know andre andre karpathy calls differentiable programming software two point o right it's like gradient descent is a better programmer than you and the idea was that in the early days of quantum computing you can only run short quantum programs and so which quantum programs should you run well just let gradient descent find mhmm those programs instead and so we built sort of the first infrastructure to not only run differentiable quantum programs but combine them as part of broader deep learning graphs incorporating deep neural networks you know the ones you know and love with what are called quantum neural networks and ultimately it was a very cross disciplinary effort we had to invent all sorts of ways to differentiate to back propagate through the graph the hybrid graph but ultimately it taught me that you the way to program matter and to program physics is by differentiating through control parameters if you have parameters that affects the physics of the system you can and you can evaluate some loss function you can optimize the system to accomplish a task whatever that task may be and that's a very sort of universal meta framework for how to program physics based computers to try to parameterize everything make those parameters differential mhmm and then optimize yes okay so is there some some more practical engineering lessons from tensorflow quantum just organizationally too like the humans involved and how to get to a product how to create good documentation how to have i don't know all all of these little subtle things that you may people might not think about i think like working across disciplinary boundaries is always a challenge and you have to be extremely patient in teaching one another right i learned a lot of software engineering through the process my colleagues learned a lot of quantum physics and some learned machine learning through the process of of building this system and i think if you get some smart people that are passionate and trust each other in a room and you have a small team and you teach each other your specialties suddenly you're kind of forming this sort of model soup of expertise and something special comes out of that right it's like combining genes but for your knowledge bases and sometimes special products come out of that and so i i think like even though it's very high friction initially to work in an interdisciplinary team i think the product at the end of the day is is is worth it and so learned a lot trying to bridge the gap there and i mean it's still a challenge to this day you know we hire folks that are have an ai background folks folks that have a pure physics background and somehow we we have to make them talk to one another right is there a magic is there some science and art to the hiring process to building a team that can create magic together yeah it's it's really hard to pinpoint that that je ne sais quoi right the i didn't know you speak french that's very nice yeah i'm i'm i'm actually french canadian so oh you are legitimately french i am i thought you were just doing that for the for the for the cred no no no i'm i'm truly french canadian from from montreal but yeah essentially we look for people with very high fluid intelligence that aren't overspecialized because they're gonna have to get out of their comfort zone they're gonna have to incorporate concepts that they've never seen before and very quickly get comfortable with them right or or learn to work in a team and so that's sort of what we look for when we hire we can't hire you know people that are just like you know optimizing this subsystem for the past three or four years we need like really general sort of broader intelligence and specialty and people that are that are open minded really because if you're pioneering a new approach from scratch there there is no textbook there's no reference it's just us and and people that are hungry to learn so we have to teach each other we have to learn the literature we have to share knowledge bases collaborate in order to push the boundary of knowledge further together right and so people that are used to just getting prescribed what to do you know at this stage when you're at the pioneering stage it's it's that's not necessarily who you want to hire yeah so you mentioned it was extrapic you're trying to build the physical substrate for generative ai mhmm what's the difference between that and the agi ai itself so is it possible that in the halls of your company agi will be created or will agi just be using this as a substrate i think our goal is to both run human like ai or anthropomorphic ai sorry for use of the term agi and i know it's triggering for you we think that the future is actually physics based ai combined with anthropomorphic ai so you can imagine i have a sort of world modeling engine through physics based ai physics based ai is better at representing the world at all scales because it can be quantum mechanical thermodynamic deterministic hybrid representations of the world just like our world at different scales has different regimes of physics if you inspire yourself from that and the ways you learn representations of nature you can have much more accurate representations of nature so you can have very accurate world models at all scales mhmm right and so you have the world modeling engine and then you have the sort of anthropomorphic ai that is human like so you can have the science the the the playground to test your ideas and you can have a synthetic scientist and to us that joint system of a physics based ai and an anthropomorphic ai is the closest thing to a fully general artificially intelligent system so you you can get closer to truth by grounding the the ai to physics right but you can also still have a anthropomorphic interface to us humans that like to talk to other humans or human like systems so on that topic what do you i suppose that is one of the big limitations of current large language models to you is that they're not they're good bullshitters they're not really grounded to truth necessarily mhmm is that would that be fair to say yeah no i i i you wouldn't you know try to extrapolate the stock market with an lm trained on text from the internet right it's not gonna be a very accurate model it's not gonna model its priors or its uncertainties about the world very accurately right so you need you need a different type of ai to complement sort of this this text extrapolation ai yeah you mentioned singularity earlier what what how far away are we from a singularity i don't know if i believe in a finite time singularity as a single point in time i think it's gonna be asymptotic and and sort of a diagonal sort of asymptote like you know we we have the light cone we have the limits of physics restricting our ability to grow so obviously can't fully diverge on a finite time i think my priors are that you know i think a lot of a lot of people on the other side of the aisle think that once we reach human level ai there's gonna be an inflection point and a sudden like foom like suddenly ai is gonna grok how to you know manipulate matter at the nanoscale and mhmm assemble nanobots and having worked you know for nearly a decade in applying ai to engineer matter it's much harder than they think and in reality you need a lot of samples from either a simulation of nature that's very accurate and costly or nature itself and that keeps your ability to control the world around us in check there's a sort of minimal cost computationally and thermodynamically to acquiring information about the world in order to be able to predict and control it and that keeps things in check it's funny you mentioned the other side of the aisle so in the poll i posted about pdoom yesterday what's the probability of doom there seems to be a nice like division between people think it's very likely and very unlikely i wonder if it's in the future there'll be the actual republicans versus democrats division blue versus red it's the ai doomers versus the eackers eiac yeah so this movement you know is not right wing or left wing fundamentally it's more like up versus down in terms of the which scale is the up okay civilization right alright but it seems to be like there is a sort of case of alignment of the existing political parties where those that are for more centralization of power control and more regulations are aligning with sort of aligning themselves with the doomers because that sort of instilling fear in people is a great way to for them to give up more control and give the government more power but fundamentally we're not left versus right i think there's we've done polls of people's alignment within eac i think it's pretty balanced so it's a it's a new fundamental issue of our time it's not just centralization versus decentralization it's kind of do we go it's like tech progressivism versus techno conservatism mhmm right so eac is as a movement is often formulated in contrast to ea effective altruism mhmm what do you think are the pros and cons of effective altruism what's interesting insightful to you about them and what is negative right i think i think like people trying to do good from first principles is is is good we should actually say and sorry to interrupt we should probably say that and you can correct me if i'm wrong but effective altruism is is a kind of movement that's trying to do good optimally where good is probably measured something like the amount of suffering in the world you wanna minimize it and there's ways that that can go wrong as any optimization can and so it's interesting to explore like how things can go wrong we're we're both trying to do good to some extent and we're we're both trying we're we're arguing for which loss function we should use right their loss function is sort of hedon's right units of hedonism like how how like how good do you feel and for how much time right and so suffering would be negative heat ons and they're trying to minimize that but to us that seems like that loss function has sort of spurious minima right you can you know start minimizing shrimp farm pain right which seems not that productive to me or you can end up with wireheading where you just you know either install a neuralink or you scroll tiktok forever and you feel good on the short term timescale because you're neurochemistry but on long term timescale it causes decay and and and death right because you're not being productive whereas sort of iac measuring progress of civilization not in terms of a subjective loss function like henot hedonism but rather an objective measure quantity that cannot be gained that is physical energy right it's very objective right and and and and and there's not many ways to game it right if you if you did it in terms of like gdp or a currency that's pinned to a certain value that's moving right and so that's not a good way to measure our progress and so but the thing is we're both trying to make progress and ensure humanity flourishes and gets to grow we just have different loss functions and different ways of going about doing it is there a degree maybe you can educate me correct me i get a little bit skeptical when there's an equation involved trying to reduce all of the human civilization human experience to an equation is there a degree that we should be skeptical of the tyranny of an equation a lot of a loss function over which to optimize like having a kind of intellectual humility about optimizing over loss functions yeah so so so this particular loss function it's not it's not stiff it's kind of an average of averages right it's like distributions of states in the future are gonna follow a certain distribution so it's not deterministic it's not like we're not on like stiff rails right it's just a statistical statement about the future but at the end of the day you know you can believe in gravity or not you know but it's not necessarily an option to obey it right and some some people try to test that and that goes not so well so similarly you know i think i think thermodynamics is there whether we like it or not and we're just trying to point out what is and and try to orient ourselves and and and chart a path forward given given this fundamental truth but there's still some uncertainty there's still lack of information humans tend to fill the gap of the lack of information with narratives mhmm and so how they interpret you know even physics is up to interpretation when there's uncertainty involved and humans tend to use that mhmm to further their own means yeah so it's always whenever there's an equation it just seems like until we have really perfect understanding of the universe humans will do what humans do and they try to use the narrative of doing good mhmm to fool the populace into doing bad yep i just i guess that this is something they should be skeptical about in all movements that's right so we invite skepticism right we do you have an understanding of what might to a degree that went wrong what do you think may have gone wrong with effective altruism that might also go wrong with effective accelerationism yeah i mean i think you know i think it provided initially a sense of community for you know engineers and intellectuals and rationalists in the early days and it seems like the community was very healthy but then you know they formed all sorts of organizations and started routing capital and having actual power right they have real power they influence the government they influence most ai orgs now i mean they're literally controlling the board of openai right and look over to anthropic and i think they'll have some control over that too and so i think you know the assumption of eac is more like capitalism is that every agent organism and meta organism is going to act in its own interests and we should maintain sort of adversarial equilibrium or or adversarial competition to keep each other in check at all times at all scales i think that yeah ultimately it was the perfect cover to acquire tons of power and capital and unfortunately sometimes that that that corrupts people over time what does a perfectly productive day since building is important what does a perfectly productive day in the life of guillaume verdun look like how how much caffeine do you consume like what what's a perfect day okay so i have a particular regimen i would say my my favorite days are twelve pm to four am and i would have meetings in the early afternoon usually external meetings some internal meetings because i'm i'm ceo i have to interface with the outside world whether it's customers or investors or renewing potential candidates and usually i'll have ketones exogenous ketones so you are on a keto on a keto diet or is this i've done keto before for football and whatnot mhmm but i i i like to have a meal after sort of part of my day is is done and so i can just have extreme focus you do the social interactions earlier in the day right without food front load them yeah yeah like right now i'm on ketones and mhmm and red bull yeah and it just gives you a clarity of thought that is that is really next level because then when you eat you're actually allocating some of your energy that could be going to neural energy to to your digestion after i eat maybe i take a break an hour or so hour and a half and then usually it's like ideally one meal a day like steak and eggs and mhmm vegetables animal based primarily so fruit and and meat and then and then i do a second wind usually that's deep work right because i'm you know i am a ceo but i'm still technical i'm contributing to most patents and there i'll just stay up late into the night and and work with engineers on very technical problems so it's like the the nine pm to four am whatever the that range of time yeah yeah that's the perfect time the the emails the the things that are on fire stop trickling in mhmm you can you can focus and then you have your second wind and you know i i think demis hassabis has a similar workday to some extent so i think that that's definitely inspired my workday but yeah i started this workday when i was at at google and had to manage a bit of the product during the day and have meetings and then and then do technical work at night exercise sleep those kinds of things yeah you said football you used to play football yeah i used to play american football i've done all sorts of sports growing up and then i was into powerlifting for a while so when i was studying mathematics in grad school i would just you know do math and lift take caffeine and that was my day it was very pure the the purest of monk modes but it's really interesting how in powerlifting you're trying to cause neural adaptation by having certain driving signals and you're trying to engineer neuroplasticity through all sorts of supplements and you know you have all sorts of you know brain derived neurotrophic factors that get secreted when you when you lift so it's it's funny to me how i was trying to engineer neural adaptation in my nervous system more broadly not just my brain while learning mathematics i think you can learn much faster if you really care if you convince yourself to care a lot about what you're learning and you have some sort of assistance let's say caffeine or some cholinergic supplement to increase neuroplasticity i should chat with andrew huberman at some point he's the expert but yeah at least to me it's like you know you can try to input more tokens into your brain if you will and you can try to increase the learning rate so that you can learn much faster on a shorter time scale so i've learned a lot of things i followed my curiosity you're naturally if you're passionate about what you're doing you're gonna learn faster you're gonna become smarter faster and if you follow your curiosity you're always going to be interested and so i advise people to follow their curiosity and don't respect the boundaries of certain fields or what you've been allocated in terms of lane of what you're working on just go out and explore and follow your nose and try to acquire and compress as much information as you can into your brain anything that you find interesting and caring about a thing and like you said which is interesting it does it works for me really well it's like tricking yourself that you care about a thing yes and then you start to really care about it yep so it's funny the motivation is a really good catalyst for learning right and so at least part part part of my character esbeth jesos is kind of like yeah yeah yeah the hype man yeah just hype but i'm like hyping myself up but then i just tweet about it yeah and it's just when i'm trying to get really hyped up and in like an altered state of consciousness where i'm like ultra focused in the flow wired trying to invent something that's never existed i need to get to like unreal levels of like excitement but your brain has these levels of of cognition that you can unlock with like higher levels of adrenaline and and whatnot and i mean i've learned that in powerlifting that actually you can engineer a mental switch to like increase your strength right like if you can engineer a switch maybe you have a prompt like a certain song or some music where suddenly you're like fully primed then you're at max maximum strength right and i've engineered that that switch through years of lifting if you're gonna get under five hundred pounds and it could crush you if you don't have that switch to be wired in you might die so that that'll wake you right up and and that sort of skill i've carried over to like research when it's when it's go time when the stakes are high somehow i just reach another level of neural performance so beth jesus is your sort of embodiment representation of your intellectual hulk it's your productivity hulk that they just turn on what what have you learned about the the nature of identity from having these two identities i think it's interesting for people to be able to put on those two hats so explicitly i think it was interesting in the early days i think in the early days i thought it was truly compartmentalized like oh yeah this is a character you know i'm guillaume beth is just the the character i like i like take my thoughts and then i extrapolate them to a bit more extreme but you know over time it's kind of like both identities were starting to merge mentally and people were like no you are i met you you are beth you are not just guillaume mhmm and i was like wait am i and now it's like fully merged but it was already before the docs it was already starting mentally that you know i'm at i am this character it's part of me would you recommend people sort of have an alt absolutely like young people would you recommend them to explore different identities by having alts alt accounts it's it's fun it's like it's like writing an essay and taking a position right it's like you you do this in debate it's it's like you can have experimental thoughts and and by having by the stakes being so low because you're an anon account with i don't know twenty followers or something you can experiment with your thoughts in in in in a low stakes environment and i feel like we've lost that in the era of everything being under your main name everything being attributable to you people just are afraid to speak explore ideas that aren't fully formed right and and i feel like we've lost something there so i i hope you know platforms like x and others like really help support people trying to stay synonymous or anonymous because it's really important for for people to share thoughts that aren't fully formed and converge onto maybe hidden truths that were hard to converge upon if it was just through open conversation with real names yeah i really believe in like not radical but rigorous empathy it's like really considering what it's like to be a person of a certain viewpoint and like taking that as a thought experiment farther and farther and farther and one way of doing that is an alt account that's a that's a that's a fun interesting way to really explore what it's like to be a person that believes a set of beliefs and taking that across the span of several days weeks months of course there's always the danger of becoming that that's that's the nietzsche gaze long into the abyss the abyss gaze into you you have to be careful breaking beth yeah right breaking beth yeah you wake up with a shaved head one day it's just like who who am i what have i become so you've mentioned quite a bit of advice already but what advice would you give to young people of how to in this interesting world we're in how to have a career and how to have a life they can be proud of i think to me the reason i went to theoretical physics was that i had to learn the base of the stack that was gonna stick around no matter yeah how the technology changes right and to me that was the foundation upon which then i later built engineering skills and other skills and to me the laws of physics you know it may seem like the landscape right now is changing so fast it's disorienting but certain things like fundamental mathematics and physics aren't going to change and if you have that knowledge and knowledge about complex systems and adaptive systems i think that's going to carry you very far and so not everybody has to study mathematics but i think it's really a huge cognitive unlock to to learn math and and some physics and engineering get as close to the base of the stack as possible yeah that's right because because the base of the stack doesn't change everything else you know your knowledge might become not as relevant in a few years of course there's a sort of transfer learning you can do but then you have to always transfer learn constantly i guess the closer you are to the base of the stack the easier the the the the easier the transfer learning the shorter the jump right right and you'd be surprised like once you've learned concepts in many physical scenarios how they can carry over to understanding other systems that aren't necessarily physics and i guess like the iac writings you know the the principles and tenet post that was based on physics that was kind of my experimentation with applying some of the thinking from out of vehicle bearing thermodynamics to understanding the world around us and it it's led to to eac and this this movement if you look at your one cog in the machine in the capitalist machine one human and if you look at yourself do you think mortality is a feature or a bug like would you want to be immortal no i i i think fundamentally in thermodynamic dissipative adaptation there's the word dissipation mhmm dissipation is important death is important right we we have a saying in physics physics progresses one funeral at a time yeah i think the same is true for capitalism companies empires people everything everything must die at some point i think that we should probably extend our lifespan because we need a longer period of of training because the world is more and more complex right we have more and more data to really be able to predict and understand the world and if we have a finite window of higher neuroplasticity then then we have sort of a hard cap in how much we can understand about our world so you know i think i am for death because again i think it's important you know if if you have like a a king that would never die that would be a problem right like it would the system wouldn't be constantly adapting right you need novelty you need youth you need disruption to make sure the system's always adapting and and and malleable otherwise if things are immortal you you know if you have let's say corporations that are there forever and they have the monopoly they get calcified they become not as optimal not as high fitness in a changing time varying landscape right and so death gives space for youth and novelty to take its place and i think it's an important part of every system in nature so yeah i am for i am for death but i do think that longer lifespan and longer time for neuroplasticity bigger brains which should be something we should strive for well in that jeff bezos and bev jaisels agree that all companies die and for jeff the the goal is to try to he calls it day one thinking try to constantly for as long as possible reinvent mhmm sort of extend the life of the company but eventually it too will die because it's so damn difficult to keep reinventing are you afraid of your own death i think i have ideas and things i'd like to achieve in this world before i have to go but i don't think i'm necessarily afraid of death you're not attached to the this particular body and mind that you got no i i i think i'm sure there's gonna be better versions of of myself in the future or forks right genetic forks or or other right i i truly i truly believe that i i think there's a sort of evolutionary like algorithm happening at at every bit or or not in in the world is sort of adapting through this process that we described in in eac and and i think maintaining this adaptation malleability is how we have constant optimization of the whole machine and so i don't think i'm particularly you know an optimum that needs to stick around forever i think there's gonna be greater optima in many ways what do you think is the meaning of it all what's the why of the machine the eac machine the why well the why is thermodynamics it's it's it's why we're here it's what has led to the formation of life and of civilization of evolution of technologies and growth of civilization but why do we have thermodynamics why do we have our particular universe why do we have these particular hyperparameters the constants of nature well then you get into the anthropic principle right in the landscape of potential universes right wherein the universe that allows for life and then why is there potentially many universes i don't know i don't know that part but could we potentially engineer new universes or create pocket universes and set the hyperparameters so there is some mutual information between our existence and that universe and we'd be somewhat its parents i think that's really i don't know that'd be very poetic it's purely conjecture but again this is why figuring out quantum gravity would allow us to understand if we can do that and above that why does it all seem so beautiful and exciting the the quest to figuring out quantum gravity seems so exciting why why is that why are we drawn to that why are we pulled towards that just just that puzzle solving creative force that underpins all of it it seems like i think we seek just like an lmcs to minimize cross entropy between its internal model and the world we seek to minimize yeah the statistical divergence between our predictions in the world and and the world itself and you know having regimes of energy scales or physical scales in which we have no visibility no ability to predict or perceive you know that's kind of an insult to us and we want to be able to understand the world better in order to best steer steer it or steer us through it and in general it's a capability that has evolved because the better you can predict the world the better you can capture utility or free energy towards your own sustenance and growth and i think quantum gravity again is kind of the the final boss in terms of knowledge acquisition because once we've mastered that then we can do a lot potentially but between here and there i think there's a lot to learn in the meso scales there's a lot of information to acquire about our world and a lot of engineering perception prediction and control to be done to climb up the kardashev scale and to us it's that's the great challenge of our times yeah and when you're not sure where to go let the meme pave the way guillaume beth thank you for talking today thank you for the work you're doing thank you for the humor and the wisdom you put into the world this was awesome thank you so much for having me lux it's a pleasure thank you for listening to this conversation with guillaume verdun to support this podcast please check out our sponsors in the description and now let me leave you with some words from albert einstein if at first the idea is not absurd then there is no hope for it thank you for listening i hope to see you next time